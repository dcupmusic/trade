{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd \n",
    "from pylab import mpl, plt\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# from operator import itemgetter\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# import math, time\n",
    "# from math import sqrt\n",
    "# import itertools\n",
    "\n",
    "# import datetime\n",
    "# from datetime import date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2ySOLdata1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "df['signal'] = df['signal'].replace({'SignalNone': 1, 'SignalLong': 2, 'SignalShort': 0})\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vbt.Data.from_data(df)\n",
    "features = data.run(\"talib\", mavp=vbt.run_arg_dict(periods=14))\n",
    "data.data['symbol'] = pd.concat([data.data['symbol'], features], axis=1)\n",
    "data.data['symbol'].drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "# This will drop columns from the DataFrame where all values are NaN\n",
    "data.data['symbol'] = data.data['symbol'].dropna(axis=1, how='all')\n",
    "\n",
    "open_price = data.get('Open')\n",
    "high_price = data.get('High')\n",
    "low_price = data.get('Low')\n",
    "close_price = data.get('Close')\n",
    "\n",
    "data.data['symbol'] = data.data['symbol'].dropna()\n",
    "predictor_list = data.data['symbol'].drop('signal', axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "X = data.data['symbol'][predictor_list]\n",
    "\n",
    "y = data.data['symbol']['signal']\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split your data into a training+validation set and a separate test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Then, split the training+validation set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, shuffle=False)  # 0.2 here means 20% of the original data, or 25% of the training+validation set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20\n",
    "\n",
    "def create_sequences(input_data, timestep):\n",
    "    sequences = []\n",
    "    data_len = len(input_data)\n",
    "    for i in range(data_len - timestep):\n",
    "        seq = input_data[i:(i + timestep)]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "X_train_list = create_sequences(X_train_scaled, timestep)\n",
    "X_test_list = create_sequences(X_test_scaled, timestep)\n",
    "X_val_list = create_sequences(X_val_scaled, timestep)\n",
    "y_train_seq_ar = y_train[timestep:]\n",
    "y_test_seq_ar = y_test[timestep:]\n",
    "y_val_seq_ar = y_val[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ar = np.array(X_train_list)\n",
    "x_test_ar = np.array(X_test_list)  \n",
    "x_val_ar = np.array(X_val_list)  \n",
    "\n",
    "y_train_seq = np.array(y_train_seq_ar).astype(int)\n",
    "y_test_seq = np.array(y_test_seq_ar).astype(int)\n",
    "y_val_seq = np.array(y_val_seq_ar).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(x_train_ar, dtype=torch.float32) # .to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(x_test_ar, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(x_val_ar, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert y_train to a numpy array if it's a tensor\n",
    "\n",
    "if isinstance(y_train_seq, torch.Tensor):\n",
    "    y_train_seq_np = y_train_seq.cpu().numpy()\n",
    "else:\n",
    "    y_train_seq_np = y_train_seq  # Assuming y_train_seq is already a numpy array or similar\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_seq_np), y=y_train_seq_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "# Move class weights to the same device as your model and data\n",
    "class_weights_tensor = class_weights_tensor.to(device)  # device could be 'cpu' or 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# our model \n",
    "\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Bidirectional LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        # The input dimension is twice the hidden_dim because it's bidirectional\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Concatenate the hidden states from both directions\n",
    "        out = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
    "        \n",
    "        # Pass the concatenated hidden states to the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:58:43,019] A new study created in memory with name: no-name-7a197f55-ee54-4b0e-a289-f2b26732face\n",
      "[I 2024-02-26 16:58:54,301] Trial 0 finished with value: 1.1375048160552979 and parameters: {'feature_idx': 92}. Best is trial 0 with value: 1.1375048160552979.\n",
      "[I 2024-02-26 16:59:05,293] Trial 1 finished with value: 0.9475595355033875 and parameters: {'feature_idx': 158}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 16:59:16,273] Trial 2 finished with value: 1.0642595291137695 and parameters: {'feature_idx': 135}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 16:59:27,289] Trial 3 finished with value: 1.1059727668762207 and parameters: {'feature_idx': 42}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 16:59:38,272] Trial 4 finished with value: 1.098615050315857 and parameters: {'feature_idx': 52}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 16:59:49,259] Trial 5 finished with value: 1.1048898696899414 and parameters: {'feature_idx': 47}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:00,228] Trial 6 finished with value: 1.0960842370986938 and parameters: {'feature_idx': 174}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:11,220] Trial 7 finished with value: 1.0981659889221191 and parameters: {'feature_idx': 14}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:22,186] Trial 8 finished with value: 1.0986032485961914 and parameters: {'feature_idx': 25}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:33,148] Trial 9 finished with value: 1.0955321788787842 and parameters: {'feature_idx': 71}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:44,122] Trial 10 finished with value: 1.0983552932739258 and parameters: {'feature_idx': 124}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:00:55,097] Trial 11 finished with value: 1.1203302145004272 and parameters: {'feature_idx': 159}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:01:06,070] Trial 12 finished with value: 1.3558531999588013 and parameters: {'feature_idx': 133}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:01:17,046] Trial 13 finished with value: 1.050742745399475 and parameters: {'feature_idx': 132}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:01:28,022] Trial 14 finished with value: 1.0736902952194214 and parameters: {'feature_idx': 109}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:01:39,016] Trial 15 finished with value: 1.1011584997177124 and parameters: {'feature_idx': 152}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:01:49,992] Trial 16 finished with value: 1.1054025888442993 and parameters: {'feature_idx': 103}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:00,987] Trial 17 finished with value: 1.082062005996704 and parameters: {'feature_idx': 151}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:11,966] Trial 18 finished with value: 1.0979286432266235 and parameters: {'feature_idx': 174}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:22,941] Trial 19 finished with value: 1.099135398864746 and parameters: {'feature_idx': 120}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:33,930] Trial 20 finished with value: 1.0984594821929932 and parameters: {'feature_idx': 83}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:44,915] Trial 21 finished with value: 1.07585871219635 and parameters: {'feature_idx': 140}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:02:55,894] Trial 22 finished with value: 0.9558120369911194 and parameters: {'feature_idx': 141}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:03:06,886] Trial 23 finished with value: 1.0683523416519165 and parameters: {'feature_idx': 161}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:03:17,873] Trial 24 finished with value: 1.0698214769363403 and parameters: {'feature_idx': 111}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:03:28,858] Trial 25 finished with value: 0.9835276007652283 and parameters: {'feature_idx': 142}. Best is trial 1 with value: 0.9475595355033875.\n",
      "[I 2024-02-26 17:03:39,840] Trial 26 finished with value: 0.7759398221969604 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:03:50,852] Trial 27 finished with value: 1.1088947057724 and parameters: {'feature_idx': 165}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:01,920] Trial 28 finished with value: 1.107414722442627 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:12,974] Trial 29 finished with value: 1.076865315437317 and parameters: {'feature_idx': 93}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:24,044] Trial 30 finished with value: 1.0981111526489258 and parameters: {'feature_idx': 121}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:35,098] Trial 31 finished with value: 0.9465425610542297 and parameters: {'feature_idx': 144}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:46,188] Trial 32 finished with value: 0.855458676815033 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:04:57,723] Trial 33 finished with value: 1.0946390628814697 and parameters: {'feature_idx': 164}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:05:08,943] Trial 34 finished with value: 1.0947426557540894 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:05:20,023] Trial 35 finished with value: 1.0962475538253784 and parameters: {'feature_idx': 129}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:05:31,047] Trial 36 finished with value: 1.0988003015518188 and parameters: {'feature_idx': 174}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:05:42,106] Trial 37 finished with value: 1.0970677137374878 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:05:53,089] Trial 38 finished with value: 1.1803627014160156 and parameters: {'feature_idx': 159}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:04,060] Trial 39 finished with value: 1.0984282493591309 and parameters: {'feature_idx': 63}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:15,043] Trial 40 finished with value: 1.0971086025238037 and parameters: {'feature_idx': 37}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:26,025] Trial 41 finished with value: 0.9017943739891052 and parameters: {'feature_idx': 138}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:37,143] Trial 42 finished with value: 1.0840739011764526 and parameters: {'feature_idx': 137}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:48,525] Trial 43 finished with value: 1.1058006286621094 and parameters: {'feature_idx': 166}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:06:59,743] Trial 44 finished with value: 1.1173417568206787 and parameters: {'feature_idx': 128}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:07:10,997] Trial 45 finished with value: 1.0950416326522827 and parameters: {'feature_idx': 117}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:07:22,221] Trial 46 finished with value: 0.9772002696990967 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:07:33,413] Trial 47 finished with value: 1.0920920372009277 and parameters: {'feature_idx': 97}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:07:44,613] Trial 48 finished with value: 1.1260274648666382 and parameters: {'feature_idx': 83}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:07:55,798] Trial 49 finished with value: 1.09732985496521 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:08:06,975] Trial 50 finished with value: 1.0947328805923462 and parameters: {'feature_idx': 135}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:08:18,136] Trial 51 finished with value: 1.1200758218765259 and parameters: {'feature_idx': 1}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:08:29,302] Trial 52 finished with value: 1.0215022563934326 and parameters: {'feature_idx': 140}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:08:40,480] Trial 53 finished with value: 0.8629863262176514 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:08:51,674] Trial 54 finished with value: 1.0420684814453125 and parameters: {'feature_idx': 169}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:02,866] Trial 55 finished with value: 1.7306525707244873 and parameters: {'feature_idx': 157}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:14,057] Trial 56 finished with value: 1.4201544523239136 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:25,253] Trial 57 finished with value: 1.1102499961853027 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:36,412] Trial 58 finished with value: 0.9859378337860107 and parameters: {'feature_idx': 132}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:47,603] Trial 59 finished with value: 1.026139497756958 and parameters: {'feature_idx': 111}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:09:58,801] Trial 60 finished with value: 1.0958644151687622 and parameters: {'feature_idx': 169}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:10:10,022] Trial 61 finished with value: 1.1268484592437744 and parameters: {'feature_idx': 143}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:10:21,206] Trial 62 finished with value: 1.1113600730895996 and parameters: {'feature_idx': 126}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:10:32,422] Trial 63 finished with value: 0.8173346519470215 and parameters: {'feature_idx': 153}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:10:43,635] Trial 64 finished with value: 1.1250171661376953 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:10:54,853] Trial 65 finished with value: 1.0986727476119995 and parameters: {'feature_idx': 162}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:11:06,068] Trial 66 finished with value: 1.0927566289901733 and parameters: {'feature_idx': 137}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:11:17,269] Trial 67 finished with value: 1.1274908781051636 and parameters: {'feature_idx': 153}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:11:28,450] Trial 68 finished with value: 0.8290621042251587 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:11:39,643] Trial 69 finished with value: 1.10135018825531 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:11:50,821] Trial 70 finished with value: 1.0413169860839844 and parameters: {'feature_idx': 169}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:02,006] Trial 71 finished with value: 0.8213781118392944 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:13,209] Trial 72 finished with value: 1.0336774587631226 and parameters: {'feature_idx': 144}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:24,422] Trial 73 finished with value: 1.0780705213546753 and parameters: {'feature_idx': 117}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:35,633] Trial 74 finished with value: 0.9896429777145386 and parameters: {'feature_idx': 132}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:46,839] Trial 75 finished with value: 1.0976148843765259 and parameters: {'feature_idx': 160}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:12:58,039] Trial 76 finished with value: 1.077196478843689 and parameters: {'feature_idx': 138}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:13:09,268] Trial 77 finished with value: 1.104382872581482 and parameters: {'feature_idx': 148}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:13:20,455] Trial 78 finished with value: 1.2502244710922241 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:13:31,638] Trial 79 finished with value: 1.1538053750991821 and parameters: {'feature_idx': 165}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:13:42,830] Trial 80 finished with value: 1.097553014755249 and parameters: {'feature_idx': 125}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:13:54,025] Trial 81 finished with value: 1.0978528261184692 and parameters: {'feature_idx': 150}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:14:05,236] Trial 82 finished with value: 1.100154995918274 and parameters: {'feature_idx': 160}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:14:16,443] Trial 83 finished with value: 0.9971933364868164 and parameters: {'feature_idx': 142}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:14:27,648] Trial 84 finished with value: 1.1035901308059692 and parameters: {'feature_idx': 174}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:14:38,844] Trial 85 finished with value: 0.793641209602356 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:14:50,035] Trial 86 finished with value: 0.9805042147636414 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:01,228] Trial 87 finished with value: 1.114150881767273 and parameters: {'feature_idx': 132}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:12,420] Trial 88 finished with value: 1.1006863117218018 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:23,622] Trial 89 finished with value: 0.9553840756416321 and parameters: {'feature_idx': 139}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:34,833] Trial 90 finished with value: 1.0987271070480347 and parameters: {'feature_idx': 74}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:45,923] Trial 91 finished with value: 1.046827793121338 and parameters: {'feature_idx': 151}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:15:57,070] Trial 92 finished with value: 1.0996440649032593 and parameters: {'feature_idx': 163}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:16:08,302] Trial 93 finished with value: 0.8592244982719421 and parameters: {'feature_idx': 157}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:16:19,530] Trial 94 finished with value: 0.8654285073280334 and parameters: {'feature_idx': 157}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:16:30,737] Trial 95 finished with value: 0.9234403967857361 and parameters: {'feature_idx': 158}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:16:41,931] Trial 96 finished with value: 0.8837199807167053 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:16:53,119] Trial 97 finished with value: 1.0908257961273193 and parameters: {'feature_idx': 168}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:17:04,356] Trial 98 finished with value: 0.880562424659729 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:17:15,616] Trial 99 finished with value: 1.093544363975525 and parameters: {'feature_idx': 164}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:17:26,849] Trial 100 finished with value: 1.1140319108963013 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:17:38,032] Trial 101 finished with value: 1.3757325410842896 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:17:49,220] Trial 102 finished with value: 1.0674891471862793 and parameters: {'feature_idx': 172}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:00,399] Trial 103 finished with value: 1.13862943649292 and parameters: {'feature_idx': 159}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:11,608] Trial 104 finished with value: 0.8490975499153137 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:22,824] Trial 105 finished with value: 1.1026219129562378 and parameters: {'feature_idx': 162}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:34,019] Trial 106 finished with value: 1.1000257730484009 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:45,192] Trial 107 finished with value: 1.0984529256820679 and parameters: {'feature_idx': 167}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:18:56,358] Trial 108 finished with value: 1.0981634855270386 and parameters: {'feature_idx': 150}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:19:07,533] Trial 109 finished with value: 1.0984455347061157 and parameters: {'feature_idx': 32}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:19:18,755] Trial 110 finished with value: 1.0275393724441528 and parameters: {'feature_idx': 157}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:19:29,887] Trial 111 finished with value: 0.9059861898422241 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:19:40,986] Trial 112 finished with value: 0.9385287761688232 and parameters: {'feature_idx': 141}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:19:52,118] Trial 113 finished with value: 1.0354379415512085 and parameters: {'feature_idx': 154}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:03,407] Trial 114 finished with value: 1.1327521800994873 and parameters: {'feature_idx': 58}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:14,467] Trial 115 finished with value: 0.9459404945373535 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:25,605] Trial 116 finished with value: 1.0725092887878418 and parameters: {'feature_idx': 135}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:36,746] Trial 117 finished with value: 1.115566611289978 and parameters: {'feature_idx': 159}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:47,942] Trial 118 finished with value: 1.0964102745056152 and parameters: {'feature_idx': 171}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:20:59,169] Trial 119 finished with value: 1.1159226894378662 and parameters: {'feature_idx': 148}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:21:10,307] Trial 120 finished with value: 1.0686161518096924 and parameters: {'feature_idx': 161}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:21:21,420] Trial 121 finished with value: 1.1411840915679932 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:21:32,673] Trial 122 finished with value: 1.5768743753433228 and parameters: {'feature_idx': 142}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:21:43,902] Trial 123 finished with value: 0.8309904932975769 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:21:55,274] Trial 124 finished with value: 1.142052173614502 and parameters: {'feature_idx': 165}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:22:06,523] Trial 125 finished with value: 0.8425084352493286 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:22:17,849] Trial 126 finished with value: 0.8330264091491699 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:22:29,418] Trial 127 finished with value: 1.1014918088912964 and parameters: {'feature_idx': 162}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:22:40,836] Trial 128 finished with value: 1.1056255102157593 and parameters: {'feature_idx': 148}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:22:52,165] Trial 129 finished with value: 0.9417983293533325 and parameters: {'feature_idx': 158}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:03,726] Trial 130 finished with value: 1.0941866636276245 and parameters: {'feature_idx': 151}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:15,028] Trial 131 finished with value: 0.8125848770141602 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:26,201] Trial 132 finished with value: 0.9751284718513489 and parameters: {'feature_idx': 157}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:37,352] Trial 133 finished with value: 1.105270266532898 and parameters: {'feature_idx': 165}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:48,499] Trial 134 finished with value: 0.9560676217079163 and parameters: {'feature_idx': 144}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:23:59,981] Trial 135 finished with value: 0.995013952255249 and parameters: {'feature_idx': 102}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:24:11,717] Trial 136 finished with value: 0.9724904894828796 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:24:23,224] Trial 137 finished with value: 1.0961592197418213 and parameters: {'feature_idx': 161}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:24:34,546] Trial 138 finished with value: 1.143134355545044 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:24:45,703] Trial 139 finished with value: 1.3361520767211914 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:24:56,804] Trial 140 finished with value: 1.1020574569702148 and parameters: {'feature_idx': 167}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:25:07,971] Trial 141 finished with value: 0.8368459343910217 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:25:19,071] Trial 142 finished with value: 1.0138553380966187 and parameters: {'feature_idx': 158}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:25:30,189] Trial 143 finished with value: 0.9929799437522888 and parameters: {'feature_idx': 147}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:25:41,290] Trial 144 finished with value: 0.9246513843536377 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:25:52,381] Trial 145 finished with value: 1.099170207977295 and parameters: {'feature_idx': 162}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:03,562] Trial 146 finished with value: 1.0692323446273804 and parameters: {'feature_idx': 151}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:14,592] Trial 147 finished with value: 0.9446203708648682 and parameters: {'feature_idx': 141}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:25,768] Trial 148 finished with value: 1.073141098022461 and parameters: {'feature_idx': 169}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:37,198] Trial 149 finished with value: 0.9201076030731201 and parameters: {'feature_idx': 158}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:48,403] Trial 150 finished with value: 1.0976213216781616 and parameters: {'feature_idx': 164}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:26:59,608] Trial 151 finished with value: 0.995898962020874 and parameters: {'feature_idx': 155}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:27:11,004] Trial 152 finished with value: 0.9052411913871765 and parameters: {'feature_idx': 153}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:27:22,348] Trial 153 finished with value: 0.8238013386726379 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:27:33,660] Trial 154 finished with value: 1.0968817472457886 and parameters: {'feature_idx': 137}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:27:44,990] Trial 155 finished with value: 0.8601863980293274 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:27:56,670] Trial 156 finished with value: 0.8343712687492371 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:28:08,000] Trial 157 finished with value: 1.0019358396530151 and parameters: {'feature_idx': 144}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:28:19,245] Trial 158 finished with value: 0.9885779619216919 and parameters: {'feature_idx': 139}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:28:30,466] Trial 159 finished with value: 1.0979022979736328 and parameters: {'feature_idx': 130}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:28:41,732] Trial 160 finished with value: 1.101635456085205 and parameters: {'feature_idx': 146}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:28:53,000] Trial 161 finished with value: 1.128401279449463 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:29:04,233] Trial 162 finished with value: 1.1275460720062256 and parameters: {'feature_idx': 143}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:29:15,492] Trial 163 finished with value: 1.0506588220596313 and parameters: {'feature_idx': 135}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:29:26,744] Trial 164 finished with value: 1.115738034248352 and parameters: {'feature_idx': 149}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:29:37,919] Trial 165 finished with value: 1.1670777797698975 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:29:49,147] Trial 166 finished with value: 1.0539337396621704 and parameters: {'feature_idx': 147}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:00,351] Trial 167 finished with value: 1.098066806793213 and parameters: {'feature_idx': 160}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:11,555] Trial 168 finished with value: 0.9496593475341797 and parameters: {'feature_idx': 141}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:22,761] Trial 169 finished with value: 1.1051660776138306 and parameters: {'feature_idx': 152}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:34,092] Trial 170 finished with value: 0.8017957210540771 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:45,257] Trial 171 finished with value: 1.0367014408111572 and parameters: {'feature_idx': 145}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:30:56,441] Trial 172 finished with value: 0.8245391845703125 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:31:07,643] Trial 173 finished with value: 1.1031379699707031 and parameters: {'feature_idx': 150}. Best is trial 26 with value: 0.7759398221969604.\n",
      "[I 2024-02-26 17:31:18,858] Trial 174 finished with value: 0.9509093165397644 and parameters: {'feature_idx': 156}. Best is trial 26 with value: 0.7759398221969604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'feature_idx': 155}\n"
     ]
    }
   ],
   "source": [
    "vbt.settings.set_theme('dark')\n",
    "vbt.settings['plotting']['layout']['width'] = 600\n",
    "vbt.settings['plotting']['layout']['height'] = 350\n",
    "\n",
    "num_epochs = 100\n",
    "num_trials = X_train_tensor.shape[2]\n",
    "\n",
    "# lets validate our technical indicators with the signal\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = 32 # trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = 2 # trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = 1e-1 # trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    step_size = 25 # trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = 0.85 # trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = 0.1 # trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    \n",
    "    # Use only the selected feature to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_val_selected = X_val_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_test_selected = X_test_tensor[:, :, feature_idx:feature_idx+1]\n",
    "  \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "    X_val_selected_gpu = X_val_selected.to(device)\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model = BiLSTMClassifier(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation step\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_output = model(X_val_selected_gpu)\n",
    "                val_loss = criterion(val_output, y_val_tensor_gpu)\n",
    "            model.train()\n",
    "\n",
    "    \n",
    "    # Return the negative total return as the objective to maximize it\n",
    "    return val_loss.item()\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 142, 156, 154, 133, 152, 154, 159, 152, 165, 149, 165, 152, 159, 92]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'study' is your completed Optuna study\n",
    "\n",
    "# Get all completed trials\n",
    "completed_trials = study.trials\n",
    "\n",
    "# Sort the trials based on their performance (assuming higher return is better)\n",
    "# Note: Adjust the sorting key based on your actual return metric if necessary\n",
    "sorted_trials = sorted(completed_trials, key=lambda trial: trial.value, reverse=True)\n",
    "\n",
    "# Get the top N performing feature indices\n",
    "top_n = 15  # For example, top 5 features\n",
    "top_n_features = [trial.params['feature_idx'] for trial in sorted_trials[:top_n]]\n",
    "\n",
    "# print(\"Top performing feature indices:\", top_n_features)\n",
    "\n",
    "# Map the indices to names\n",
    "top_performing_feature_names = [predictor_list[idx] for idx in top_n_features]\n",
    "# top_performing_feature_names\n",
    "top_n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs_2 = 100\n",
    "num_trials_2 = 100\n",
    "\n",
    "def objective_2(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    step_size = trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    # feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    # Suggest a boolean flag for each feature to decide if it should be included\n",
    "    # num_features = X_train_tensor.shape[2]  # assuming the last dimension is the feature dimension\n",
    "    # included_features = [trial.suggest_categorical(f'include_top_feature_{i}', [True, False]) for i in top_n_features]\n",
    "\n",
    "    # included_features_idx = [i for i, f in enumerate(included_features) if f]\n",
    "    \n",
    "    # If no features are selected, we can either skip this trial or select a default feature\n",
    "    # if not included_features_idx:\n",
    "    #     return None  # Or handle this case as you see fit\n",
    "    \n",
    "    # Use only the selected features to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, top_n_features]\n",
    "    X_val_selected = X_val_tensor[:, :, top_n_features]\n",
    "    X_test_selected = X_test_tensor[:, :, top_n_features]\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model_2 = BiLSTMClassifier(input_dim=len(top_n_features), hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model_2.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    model_2.train()\n",
    "    for epoch in range(num_epochs_2):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model_2(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "    model_2.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model_2(X_test_selected_gpu)\n",
    "        probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "\n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    df_split = data.data['symbol'][-len(predicted_labels_numpy):].copy()\n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 2\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        long_exits=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "\n",
    "    stats = pf.stats()\n",
    "    total_return = stats['Total Return [%]']\n",
    "    orders = stats['Total Orders']\n",
    "\n",
    "    if orders < 10:\n",
    "        print(f\"Only {orders} trades were made\")\n",
    "        total_return = 0.0\n",
    "    if total_return > 120:\n",
    "        pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "    \n",
    "    # Return the negative total return as the objective to maximize it\n",
    "    return total_return\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study_2 = optuna.create_study(direction='maximize')\n",
    "study_2.optimize(objective_2, n_trials=num_trials_2)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'study' is your completed Optuna study\n",
    "\n",
    "\n",
    "best_trial_2 = study_2.best_trial\n",
    "\n",
    "print(f\"Best trial number: {best_trial_2.number}\")\n",
    "print(\"Best trial's parameters:\", best_trial_2.params)\n",
    "print(\"Best trial's objective value:\", best_trial_2.value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_trial.params is your dictionary\n",
    "params_2 = best_trial_2.params\n",
    "\n",
    "# Extracting feature indices for which the value is True\n",
    "included_feature_indices = [int(key.split('_')[-1]) for key, value in params_2.items() if value]\n",
    "\n",
    "print(\"Included feature indices:\", included_feature_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the indices to names\n",
    "top_performing_feature_names = [predictor_list[idx] for idx in included_feature_indices]\n",
    "\n",
    "print(\"Top performing feature names:\", top_performing_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
