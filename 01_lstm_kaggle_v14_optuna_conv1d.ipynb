{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pylab import mpl, plt\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2ySOLdata1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "df['signal'] = df['signal'].replace({'SignalNone': 1, 'SignalLong': 2, 'SignalShort': 0})\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vbt.Data.from_data(df)\n",
    "features = data.run(\"talib\", mavp=vbt.run_arg_dict(periods=14))\n",
    "data.data['symbol'] = pd.concat([data.data['symbol'], features], axis=1)\n",
    "data.data['symbol'].drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "# This will drop columns from the DataFrame where all values are NaN\n",
    "data.data['symbol'] = data.data['symbol'].dropna(axis=1, how='all')\n",
    "\n",
    "open_price = data.get('Open')\n",
    "high_price = data.get('High')\n",
    "low_price = data.get('Low')\n",
    "close_price = data.get('Close')\n",
    "\n",
    "data.data['symbol'] = data.data['symbol'].dropna()\n",
    "predictor_list = data.data['symbol'].drop('signal', axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "X = data.data['symbol'][predictor_list]\n",
    "\n",
    "y = data.data['symbol']['signal']\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split your data into a training+validation set and a separate test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Then, split the training+validation set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, shuffle=False)  # 0.2 here means 20% of the original data, or 25% of the training+validation set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20\n",
    "\n",
    "def create_sequences(input_data, timestep):\n",
    "    sequences = []\n",
    "    data_len = len(input_data)\n",
    "    for i in range(data_len - timestep):\n",
    "        seq = input_data[i:(i + timestep)]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "X_train_list = create_sequences(X_train_scaled, timestep)\n",
    "X_test_list = create_sequences(X_test_scaled, timestep)\n",
    "X_val_list = create_sequences(X_val_scaled, timestep)\n",
    "y_train_seq_ar = y_train[timestep:]\n",
    "y_test_seq_ar = y_test[timestep:]\n",
    "y_val_seq_ar = y_val[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ar = np.array(X_train_list)\n",
    "x_test_ar = np.array(X_test_list)  \n",
    "x_val_ar = np.array(X_val_list)  \n",
    "\n",
    "y_train_seq = np.array(y_train_seq_ar).astype(int)\n",
    "y_test_seq = np.array(y_test_seq_ar).astype(int)\n",
    "y_val_seq = np.array(y_val_seq_ar).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(x_train_ar, dtype=torch.float32) # .to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(x_test_ar, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(x_val_ar, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert y_train to a numpy array if it's a tensor\n",
    "if isinstance(y_train_seq, torch.Tensor):\n",
    "    y_train_seq_np = y_train_seq.cpu().numpy()\n",
    "else:\n",
    "    y_train_seq_np = y_train_seq  # Assuming y_train_seq is already a numpy array or similar\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_seq_np), y=y_train_seq_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "# Move class weights to the same device as your model and data\n",
    "class_weights_tensor = class_weights_tensor.to(device)  # device could be 'cpu' or 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        # Note: Adjust in_channels, out_channels, kernel_size, stride, padding as per your requirements\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # Intermediate layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer\n",
    "        \n",
    "        # Additional Dropout for the fully connected layer\n",
    "        self.dropout_fc = nn.Dropout(dropout_rate / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, input_dim]\n",
    "        # Conv1d expects input in shape [batch_size, channels, sequence_length]\n",
    "        x = x.permute(0, 2, 1)  # Reshape x to [batch_size, input_dim, sequence_length]\n",
    "        \n",
    "        # Convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape back to [batch_size, sequence_length, hidden_dim] for LSTM\n",
    "        \n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Concatenate the hidden states from both directions\n",
    "        out = torch.cat((out[:, -1, :self.hidden_dim], out[:, 0, self.hidden_dim:]), dim=1)\n",
    "        \n",
    "        # Passing through the fully connected layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout_fc(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:02:05,022] A new study created in memory with name: no-name-7f28815a-2901-4353-b488-162d1bcb8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.6776315789473685\n",
      "Validation Accuracy (excluding 'hold'): 0.9354838709677419\n",
      "Validation Accuracy (excluding 'hold'): 0.9391304347826087\n",
      "Validation Accuracy (excluding 'hold'): 0.9285714285714286\n",
      "Validation Accuracy (excluding 'hold'): 0.9090909090909091\n",
      "Validation Accuracy (excluding 'hold'): 0.9423076923076923\n",
      "Validation Accuracy (excluding 'hold'): 0.9090909090909091\n",
      "Validation Accuracy (excluding 'hold'): 0.8974358974358975\n",
      "Validation Accuracy (excluding 'hold'): 0.9354838709677419\n",
      "Validation Accuracy (excluding 'hold'): 0.9259259259259259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:03:00,047] Trial 0 finished with value: 0.9259259259259259 and parameters: {'feature_idx': 173}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.46534653465346537\n",
      "Validation Accuracy (excluding 'hold'): 0.47126436781609193\n",
      "Validation Accuracy (excluding 'hold'): 0.5052631578947369\n",
      "Validation Accuracy (excluding 'hold'): 0.5131578947368421\n",
      "Validation Accuracy (excluding 'hold'): 0.5\n",
      "Validation Accuracy (excluding 'hold'): 0.45454545454545453\n",
      "Validation Accuracy (excluding 'hold'): 0.40816326530612246\n",
      "Validation Accuracy (excluding 'hold'): 0.38095238095238093\n",
      "Validation Accuracy (excluding 'hold'): 0.3902439024390244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:03:55,098] Trial 1 finished with value: 0.3902439024390244 and parameters: {'feature_idx': 92}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5\n",
      "Validation Accuracy (excluding 'hold'): 0.4728682170542636\n",
      "Validation Accuracy (excluding 'hold'): 0.4728682170542636\n",
      "Validation Accuracy (excluding 'hold'): 0.4728682170542636\n",
      "Validation Accuracy (excluding 'hold'): 0.4765625\n",
      "Validation Accuracy (excluding 'hold'): 0.4765625\n",
      "Validation Accuracy (excluding 'hold'): 0.4765625\n",
      "Validation Accuracy (excluding 'hold'): 0.4765625\n",
      "Validation Accuracy (excluding 'hold'): 0.4765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:04:49,789] Trial 2 finished with value: 0.4765625 and parameters: {'feature_idx': 37}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.4943820224719101\n",
      "Validation Accuracy (excluding 'hold'): 0.518796992481203\n",
      "Validation Accuracy (excluding 'hold'): 0.5\n",
      "Validation Accuracy (excluding 'hold'): 0.5058823529411764\n",
      "Validation Accuracy (excluding 'hold'): 0.5172413793103449\n",
      "Validation Accuracy (excluding 'hold'): 0.5180722891566265\n",
      "Validation Accuracy (excluding 'hold'): 0.5176470588235295\n",
      "Validation Accuracy (excluding 'hold'): 0.5227272727272727\n",
      "Validation Accuracy (excluding 'hold'): 0.5274725274725275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:05:44,817] Trial 3 finished with value: 0.5274725274725275 and parameters: {'feature_idx': 130}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5220588235294118\n",
      "Validation Accuracy (excluding 'hold'): 0.652542372881356\n",
      "Validation Accuracy (excluding 'hold'): 0.6532258064516129\n",
      "Validation Accuracy (excluding 'hold'): 0.6585365853658537\n",
      "Validation Accuracy (excluding 'hold'): 0.6486486486486487\n",
      "Validation Accuracy (excluding 'hold'): 0.6724137931034483\n",
      "Validation Accuracy (excluding 'hold'): 0.6476190476190476\n",
      "Validation Accuracy (excluding 'hold'): 0.6224489795918368\n",
      "Validation Accuracy (excluding 'hold'): 0.6444444444444445\n",
      "Validation Accuracy (excluding 'hold'): 0.6511627906976745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:06:39,357] Trial 4 finished with value: 0.6511627906976745 and parameters: {'feature_idx': 167}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:07:33,900] Trial 5 finished with value: 0.0 and parameters: {'feature_idx': 62}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:08:28,371] Trial 6 finished with value: 0.0 and parameters: {'feature_idx': 33}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5555555555555556\n",
      "Validation Accuracy (excluding 'hold'): 0.5136986301369864\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n",
      "Validation Accuracy (excluding 'hold'): 0.5174825174825175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:09:22,873] Trial 7 finished with value: 0.5174825174825175 and parameters: {'feature_idx': 44}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.5945945945945946\n",
      "Validation Accuracy (excluding 'hold'): 0.5648854961832062\n",
      "Validation Accuracy (excluding 'hold'): 0.5909090909090909\n",
      "Validation Accuracy (excluding 'hold'): 0.5769230769230769\n",
      "Validation Accuracy (excluding 'hold'): 0.5769230769230769\n",
      "Validation Accuracy (excluding 'hold'): 0.5769230769230769\n",
      "Validation Accuracy (excluding 'hold'): 0.6153846153846154\n",
      "Validation Accuracy (excluding 'hold'): 0.6153846153846154\n",
      "Validation Accuracy (excluding 'hold'): 0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:10:17,425] Trial 8 finished with value: 0.6153846153846154 and parameters: {'feature_idx': 59}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.8287671232876712\n",
      "Validation Accuracy (excluding 'hold'): 0.7244094488188977\n",
      "Validation Accuracy (excluding 'hold'): 0.7087378640776699\n",
      "Validation Accuracy (excluding 'hold'): 0.75\n",
      "Validation Accuracy (excluding 'hold'): 0.7419354838709677\n",
      "Validation Accuracy (excluding 'hold'): 0.7017543859649122\n",
      "Validation Accuracy (excluding 'hold'): 0.7333333333333333\n",
      "Validation Accuracy (excluding 'hold'): 0.75\n",
      "Validation Accuracy (excluding 'hold'): 0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:11:11,993] Trial 9 finished with value: 0.7692307692307693 and parameters: {'feature_idx': 147}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.7681159420289855\n",
      "Validation Accuracy (excluding 'hold'): 0.7638888888888888\n",
      "Validation Accuracy (excluding 'hold'): 0.8194444444444444\n",
      "Validation Accuracy (excluding 'hold'): 0.8231292517006803\n",
      "Validation Accuracy (excluding 'hold'): 0.8461538461538461\n",
      "Validation Accuracy (excluding 'hold'): 0.8461538461538461\n",
      "Validation Accuracy (excluding 'hold'): 0.8571428571428571\n",
      "Validation Accuracy (excluding 'hold'): 0.875\n",
      "Validation Accuracy (excluding 'hold'): 0.8796992481203008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:12:06,630] Trial 10 finished with value: 0.8796992481203008 and parameters: {'feature_idx': 105}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.45614035087719296\n",
      "Validation Accuracy (excluding 'hold'): 0.7123287671232876\n",
      "Validation Accuracy (excluding 'hold'): 0.8571428571428571\n",
      "Validation Accuracy (excluding 'hold'): 0.8413793103448276\n",
      "Validation Accuracy (excluding 'hold'): 0.8785714285714286\n",
      "Validation Accuracy (excluding 'hold'): 0.8785714285714286\n",
      "Validation Accuracy (excluding 'hold'): 0.8776978417266187\n",
      "Validation Accuracy (excluding 'hold'): 0.8740740740740741\n",
      "Validation Accuracy (excluding 'hold'): 0.8712121212121212\n",
      "Validation Accuracy (excluding 'hold'): 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:13:01,449] Trial 11 finished with value: 0.88 and parameters: {'feature_idx': 105}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5985915492957746\n",
      "Validation Accuracy (excluding 'hold'): 0.636986301369863\n",
      "Validation Accuracy (excluding 'hold'): 0.6616541353383458\n",
      "Validation Accuracy (excluding 'hold'): 0.6524822695035462\n",
      "Validation Accuracy (excluding 'hold'): 0.6830985915492958\n",
      "Validation Accuracy (excluding 'hold'): 0.6541353383458647\n",
      "Validation Accuracy (excluding 'hold'): 0.6666666666666666\n",
      "Validation Accuracy (excluding 'hold'): 0.6451612903225806\n",
      "Validation Accuracy (excluding 'hold'): 0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:13:56,598] Trial 12 finished with value: 0.640625 and parameters: {'feature_idx': 2}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5714285714285714\n",
      "Validation Accuracy (excluding 'hold'): 0.5815602836879432\n",
      "Validation Accuracy (excluding 'hold'): 0.6343283582089553\n",
      "Validation Accuracy (excluding 'hold'): 0.5970149253731343\n",
      "Validation Accuracy (excluding 'hold'): 0.5735294117647058\n",
      "Validation Accuracy (excluding 'hold'): 0.5362318840579711\n",
      "Validation Accuracy (excluding 'hold'): 0.5766423357664233\n",
      "Validation Accuracy (excluding 'hold'): 0.5942028985507246\n",
      "Validation Accuracy (excluding 'hold'): 0.5923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:14:52,180] Trial 13 finished with value: 0.5923076923076923 and parameters: {'feature_idx': 125}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.4625\n",
      "Validation Accuracy (excluding 'hold'): 0.4838709677419355\n",
      "Validation Accuracy (excluding 'hold'): 0.48333333333333334\n",
      "Validation Accuracy (excluding 'hold'): 0.47619047619047616\n",
      "Validation Accuracy (excluding 'hold'): 0.5319148936170213\n",
      "Validation Accuracy (excluding 'hold'): 0.4666666666666667\n",
      "Validation Accuracy (excluding 'hold'): 0.5544554455445545\n",
      "Validation Accuracy (excluding 'hold'): 0.5188679245283019\n",
      "Validation Accuracy (excluding 'hold'): 0.5185185185185185\n",
      "Validation Accuracy (excluding 'hold'): 0.5377358490566038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:15:47,132] Trial 14 finished with value: 0.5377358490566038 and parameters: {'feature_idx': 166}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.6982758620689655\n",
      "Validation Accuracy (excluding 'hold'): 0.7466666666666667\n",
      "Validation Accuracy (excluding 'hold'): 0.7272727272727273\n",
      "Validation Accuracy (excluding 'hold'): 0.6842105263157895\n",
      "Validation Accuracy (excluding 'hold'): 0.6666666666666666\n",
      "Validation Accuracy (excluding 'hold'): 0.6551724137931034\n",
      "Validation Accuracy (excluding 'hold'): 0.5833333333333334\n",
      "Validation Accuracy (excluding 'hold'): 0.6\n",
      "Validation Accuracy (excluding 'hold'): 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:16:42,155] Trial 15 finished with value: 0.6 and parameters: {'feature_idx': 113}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.8372093023255814\n",
      "Validation Accuracy (excluding 'hold'): 0.8879310344827587\n",
      "Validation Accuracy (excluding 'hold'): 0.8387096774193549\n",
      "Validation Accuracy (excluding 'hold'): 0.8333333333333334\n",
      "Validation Accuracy (excluding 'hold'): 0.8490566037735849\n",
      "Validation Accuracy (excluding 'hold'): 0.8604651162790697\n",
      "Validation Accuracy (excluding 'hold'): 0.8536585365853658\n",
      "Validation Accuracy (excluding 'hold'): 0.8421052631578947\n",
      "Validation Accuracy (excluding 'hold'): 0.8378378378378378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:17:37,264] Trial 16 finished with value: 0.8378378378378378 and parameters: {'feature_idx': 142}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.47368421052631576\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:18:31,949] Trial 17 finished with value: 0.5263157894736842 and parameters: {'feature_idx': 79}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.5348837209302325\n",
      "Validation Accuracy (excluding 'hold'): 0.56\n",
      "Validation Accuracy (excluding 'hold'): 0.6762589928057554\n",
      "Validation Accuracy (excluding 'hold'): 0.6595744680851063\n",
      "Validation Accuracy (excluding 'hold'): 0.6137931034482759\n",
      "Validation Accuracy (excluding 'hold'): 0.6344827586206897\n",
      "Validation Accuracy (excluding 'hold'): 0.6301369863013698\n",
      "Validation Accuracy (excluding 'hold'): 0.6433566433566433\n",
      "Validation Accuracy (excluding 'hold'): 0.624113475177305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-27 11:19:26,705] Trial 18 finished with value: 0.624113475177305 and parameters: {'feature_idx': 174}. Best is trial 0 with value: 0.9259259259259259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (excluding 'hold'): 0.5263157894736842\n",
      "Validation Accuracy (excluding 'hold'): 0.4696969696969697\n",
      "Validation Accuracy (excluding 'hold'): 0.48175182481751827\n",
      "Validation Accuracy (excluding 'hold'): 0.4661016949152542\n",
      "Validation Accuracy (excluding 'hold'): 0.5416666666666666\n",
      "Validation Accuracy (excluding 'hold'): 0.5384615384615384\n",
      "Validation Accuracy (excluding 'hold'): 0.5213675213675214\n",
      "Validation Accuracy (excluding 'hold'): 0.5299145299145299\n"
     ]
    }
   ],
   "source": [
    "# vbt.settings.set_theme('dark')\n",
    "# vbt.settings['plotting']['layout']['width'] = 500\n",
    "# vbt.settings['plotting']['layout']['height'] = 250\n",
    "\n",
    "num_epochs = 500\n",
    "num_trials = 20 # X_train_tensor.shape[2]\n",
    "min_total_return = 5\n",
    "# lets validate our technical indicators with the signal\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = 32 # trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = 2 # trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = 1e-2 # trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    step_size = 25 # trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = 0.85 # trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = 0.1 # trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    \n",
    "    # Use only the selected feature to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_val_selected = X_val_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_test_selected = X_test_tensor[:, :, feature_idx:feature_idx+1]\n",
    "  \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "    X_val_selected_gpu = X_val_selected.to(device)\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model = BiLSTMClassifier(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # # Validation step\n",
    "        if epoch % 50 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_output = model(X_val_selected_gpu)\n",
    "                val_loss = criterion(val_output, y_val_tensor_gpu)\n",
    "                # Convert model outputs to predicted classes\n",
    "                _, predicted_classes = torch.max(val_output, 1)\n",
    "                \n",
    "                # Convert tensors to numpy arrays for compatibility with sklearn\n",
    "                predicted_classes = predicted_classes.cpu().numpy()\n",
    "                true_classes = y_val_tensor_gpu.cpu().numpy()\n",
    "                \n",
    "                # Filter out 'hold' predictions and labels\n",
    "                buy_sell_filter = (true_classes != 1) & (predicted_classes != 1)\n",
    "                filtered_true_classes = true_classes[buy_sell_filter]\n",
    "                filtered_predicted_classes = predicted_classes[buy_sell_filter]\n",
    "                \n",
    "                if len(filtered_predicted_classes) > 0 and len(filtered_true_classes) > 0:\n",
    "                    accuracy = accuracy_score(filtered_true_classes, filtered_predicted_classes)\n",
    "                    print(f\"Validation Accuracy (excluding 'hold'): {accuracy}\")\n",
    "                else:\n",
    "                    # print(\"Filtered classes are empty. Skipping accuracy calculation.\")\n",
    "                    accuracy = 0  # or some default value\n",
    "                \n",
    "            model.train()\n",
    "    # Return the loss as the objective to minimize it\n",
    "    return accuracy\n",
    "    # return val_loss.item()\n",
    "        \n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     y_test_pred = model(X_test_selected_gpu)\n",
    "    #     probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "    #     _, predicted_labels = torch.max(probabilities, 1)\n",
    "    #     predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "    \n",
    "    # # Use predicted labels to simulate a trading strategy\n",
    "    # df_split = data.data['symbol'][-len(predicted_labels_numpy):].copy()\n",
    "    # df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    # signal = df_split['signal']\n",
    "    # entries = signal == 2\n",
    "    # exits = signal == 0\n",
    "    # pf = vbt.Portfolio.from_signals(\n",
    "    #     close=df_split.Close, \n",
    "    #     long_entries=entries, \n",
    "    #     long_exits=exits,\n",
    "    #     size=100,\n",
    "    #     size_type='value',\n",
    "    #     init_cash='auto'\n",
    "    # )\n",
    "    # stats = pf.stats()\n",
    "    # total_return = stats['Total Return [%]']\n",
    "    # orders = stats['Total Orders']\n",
    "\n",
    "    # if orders < 10:\n",
    "    #     print(f\"Only {orders} trades were made\")\n",
    "    #     total_return = 0.0\n",
    "    # if total_return > min_total_return:\n",
    "    #     pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "    \n",
    "    # # Return the negative total return as the objective to maximize it\n",
    "    # return total_return\n",
    "\n",
    "\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'study' is your completed Optuna study\n",
    "\n",
    "# Get all completed trials\n",
    "completed_trials = study.trials\n",
    "\n",
    "# Sort the trials based on their performance (assuming higher return is better)\n",
    "# Note: Adjust the sorting key based on your actual return metric if necessary\n",
    "sorted_trials = sorted(completed_trials, key=lambda trial: trial.value, reverse=True)\n",
    "\n",
    "# Get the top N performing feature indices\n",
    "top_n = 4  # For example, top 5 features\n",
    "top_n_features = [trial.params['feature_idx'] for trial in sorted_trials[:top_n]]\n",
    "\n",
    "# print(\"Top performing feature indices:\", top_n_features)\n",
    "\n",
    "# Map the indices to names\n",
    "top_performing_feature_names = [predictor_list[idx] for idx in top_n_features]\n",
    "top_performing_feature_names\n",
    "# top_n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs_2 = 50\n",
    "num_trials_2 = 10\n",
    "min_total_return = 50\n",
    "\n",
    "\n",
    "def objective_2(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    step_size = trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    # feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    # Suggest a boolean flag for each feature to decide if it should be included\n",
    "    # num_features = X_train_tensor.shape[2]  # assuming the last dimension is the feature dimension\n",
    "    # included_features = [trial.suggest_categorical(f'include_top_feature_{i}', [True, False]) for i in top_n_features]\n",
    "\n",
    "    # included_features_idx = [i for i, f in enumerate(included_features) if f]\n",
    "    \n",
    "    # # If no features are selected, we can either skip this trial or select a default feature\n",
    "    # if not included_features_idx:\n",
    "    #     return None  # Or handle this case as you see fit\n",
    "    \n",
    "    # Use only the selected features to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, top_n_features]\n",
    "    X_val_selected = X_val_tensor[:, :, top_n_features]\n",
    "    X_test_selected = X_test_tensor[:, :, top_n_features]\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model_2 = BiLSTMClassifier(input_dim=len(top_n_features), hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model_2.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    model_2.train()\n",
    "    for epoch in range(num_epochs_2):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model_2(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "    model_2.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model_2(X_test_selected_gpu)\n",
    "        probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "\n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    df_split = data.data['symbol'][-len(predicted_labels_numpy):].copy()\n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 2\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        long_exits=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "\n",
    "    stats = pf.stats()\n",
    "    total_return = stats['Total Return [%]']\n",
    "    orders = stats['Total Orders']\n",
    "\n",
    "    if orders < 10:\n",
    "        print(f\"Only {orders} trades were made\")\n",
    "        total_return = 0.0\n",
    "    if total_return > min_total_return:\n",
    "        pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "    \n",
    "    # Return the negative total return as the objective to maximize it\n",
    "    return total_return\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study_2 = optuna.create_study(direction='maximize')\n",
    "study_2.optimize(objective_2, n_trials=num_trials_2)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'study' is your completed Optuna study\n",
    "\n",
    "\n",
    "best_trial_2 = study_2.best_trial\n",
    "\n",
    "print(f\"Best trial number: {best_trial_2.number}\")\n",
    "print(\"Best trial's parameters:\", best_trial_2.params)\n",
    "print(\"Best trial's objective value:\", best_trial_2.value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_trial.params is your dictionary\n",
    "params_2 = best_trial_2.params\n",
    "\n",
    "# Extracting feature indices for which the value is True\n",
    "included_feature_indices = [int(key.split('_')[-1]) for key, value in params_2.items() if value]\n",
    "\n",
    "print(\"Included feature indices:\", included_feature_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the indices to names\n",
    "top_performing_feature_names = [predictor_list[idx] for idx in included_feature_indices]\n",
    "\n",
    "print(\"Top performing feature names:\", top_performing_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
