{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qq80stCGSiDw"
   },
   "source": [
    "# Notebook Instructions\n",
    "<i>You can run the notebook document sequentially (one cell a time) by pressing <b> shift + enter</b>. While a cell is running, a [*] will display on the left. When it has been run, a number will display indicating the order in which it was run in the notebook [8].</i>\n",
    "\n",
    "<i>Enter edit mode by pressing <b>`Enter`</b> or using the mouse to click on a cell's editor area. Edit mode is indicated by a green cell border and a prompt showing in the editor area.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qxx8CEodSiD0"
   },
   "source": [
    "# Cross validation\n",
    "\n",
    "Cross validation technique is used to estimate the performance of the model on a multiple train-validation set split. In this notebook, we implement a k-fold cross validation method to evaluate the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4BW3qRGSiD2"
   },
   "source": [
    "## Create a random forest model - you already know this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqFFoQBLSiD4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('../data_modules/AAPL_2008_2018.csv')\n",
    "\n",
    "# Returns\n",
    "data['ret1'] = data.Adj_Close.pct_change()\n",
    "data['ret5'] = data['ret1'].rolling(5).sum()\n",
    "data['ret10'] = data['ret1'].rolling(10).sum()\n",
    "data['ret20'] = data['ret1'].rolling(20).sum()\n",
    "data['ret40'] = data['ret1'].rolling(40).sum()\n",
    "\n",
    "# Standard Deviation\n",
    "data['std5'] = data['ret1'].rolling(5).std()\n",
    "data['std10'] = data['ret1'].rolling(10).std()\n",
    "data['std20'] = data['ret1'].rolling(20).std()\n",
    "data['std40'] = data['ret1'].rolling(40).std()\n",
    "\n",
    "# Future returns\n",
    "data['retFut1'] = data.ret1.shift(-1)\n",
    "\n",
    "# Define predictor variables (X) and a target variable (y)\n",
    "data = data.dropna()\n",
    "predictor_list = ['ret1', 'ret5', 'ret10', 'ret20',\n",
    "                  'ret40', 'std5', 'std10', 'std20', 'std40']\n",
    "X = data[predictor_list]\n",
    "y = np.where(data.retFut1 > 0, 1, -1)\n",
    "\n",
    "seed = 42\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=20,\n",
    "    max_features=0.6,\n",
    "    min_samples_leaf=400,\n",
    "    random_state=seed,\n",
    "    bootstrap=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMfjApQLSiD-"
   },
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "The KFold function from sklearn.model_selection package uses the train/test indices to split the data into k consecutive sets of train/test.\n",
    "\n",
    "The parameters are:\n",
    "1. n_splits= number of folds. It must be at least 2\n",
    "2. shuffle= True/False, if the data should be shuffled before splitting into batches\n",
    "\n",
    "And, we have used a cross_val_score function from the model selection module to do cross-validation. The function cross_val_score takes as input\n",
    "\n",
    "1. estimator model\n",
    "2. predictor variables\n",
    "3. target variable\n",
    "4. number of folds (cv).\n",
    "The function returns an array of scores of the estimator for each run of the cross-validation. You can use the help function to see the details of the cross_val_score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osWmwJj0SiD_",
    "outputId": "fd160886-ae20-4707-d15d-51e1b64e1db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x287dec160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Split dataset into k consecutive folds\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "kf.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDwTd1OkSiEC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53137255 0.56862745 0.51372549 0.51866405 0.52455796]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Returns an array of scores of the estimator\n",
    "scores = cross_val_score(random_forest, X, y, cv=kf.split(X))\n",
    "\n",
    "# Print the scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aS1sjvCQSiEE"
   },
   "source": [
    "After running cross validation we end up with 5 (number of folds) performance scores that is summarized using a mean and a standard deviation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLYoksSKSiEF",
    "outputId": "570e641c-e1a3-4425-900c-4deae12b7987"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 53.139% (1.953%)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy: %.3f%% (%.3f%%)\" % (scores.mean()*100.0, scores.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwyIsoyMSiEI"
   },
   "source": [
    "The above cross-validation accuracy scores and standard deviation provides a more reliable measure to evaluate the performance of the model because the model is trained and evaluated on different data. Here, we have used the k-fold method to evaluate the random forest classifier model.\n",
    "<BR>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cross Validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
