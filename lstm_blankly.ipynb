{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorbtpro as vbt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "vbt.settings.set_theme('dark')\n",
    "vbt.settings['plotting']['layout']['width'] = 800\n",
    "vbt.settings['plotting']['layout']['height'] = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_gen(data, seq_length,output_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    #Loop through data, adding input data to x array and output data to y array\n",
    "    for i in range(len(data)-seq_length):\n",
    "        _x = data[i:(i+seq_length - output_size)]\n",
    "        _y = data[i+seq_length - output_size:i + seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/twdts0414gn1_4rw0fsqsphm0000gn/T/ipykernel_1864/1816512338.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['signal'] = df['signal'].replace({'SignalNone': 0, 'SignalLong': 1, 'SignalShort': -1})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('2ySOLdata1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "df['signal'] = df['signal'].replace({'SignalNone': 0, 'SignalLong': 1, 'SignalShort': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink_size = int(0.1*(len(df)))\n",
    "mini_df = df[-shrink_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vbt.Data.from_data(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_price = data.get('Open')\n",
    "high_price = data.get('High')\n",
    "low_price = data.get('Low')\n",
    "close_price = data.get('Close')\n",
    "\n",
    "adx = vbt.ADX.run(high_price, low_price, close_price, window=14)\n",
    "atr = vbt.ATR.run(high_price, low_price, close_price, window=14)\n",
    "bbands = vbt.BBANDS.run(close_price, window=14)\n",
    "rsi = vbt.RSI.run(close_price)\n",
    "sma = vbt.MA.run(close_price, window=20)\n",
    "strend = vbt.SUPERTREND.run(high_price, low_price, close_price, period=7, multiplier=3)\n",
    "\n",
    "data.data['symbol']['ADX'] = adx.adx\n",
    "data.data['symbol']['ATR'] = atr.atr\n",
    "data.data['symbol']['BBAND'] = bbands.bandwidth\n",
    "data.data['symbol']['RSI'] = rsi.rsi\n",
    "data.data['symbol']['SMA'] = sma.ma\n",
    "data.data['symbol']['STREND'] = strend.trend\n",
    "data.data['symbol'] = data.data['symbol'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_list = ['Open', 'High', 'Low', 'Close', 'Volume', 'ADX', 'ATR', 'BBAND', 'RSI', 'SMA', 'STREND']\n",
    "\n",
    "X = data.data['symbol'][predictor_list]\n",
    "\n",
    "y = data.data['symbol']['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.3*(len(X)))\n",
    "X_train = X[:-test_size]\n",
    "X_test = X[-test_size:]\n",
    "\n",
    "y_train = y[:-test_size]\n",
    "y_test = y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "\n",
    "X_train_scaled=scl.fit_transform(X_train)\n",
    "X_train= X_train.assign(Open=X_train_scaled[:, 0])\n",
    "X_train= X_train.assign(High=X_train_scaled[:, 1])\n",
    "X_train= X_train.assign(Low=X_train_scaled[:, 2])\n",
    "X_train= X_train.assign(Close=X_train_scaled[:, 3])\n",
    "X_train= X_train.assign(Volume=X_train_scaled[:, 4])\n",
    "X_train= X_train.assign(ADX=X_train_scaled[:, 5])\n",
    "X_train= X_train.assign(ATR=X_train_scaled[:, 6])\n",
    "X_train= X_train.assign(BBAND=X_train_scaled[:, 7])\n",
    "X_train= X_train.assign(RSI=X_train_scaled[:, 8])\n",
    "X_train= X_train.assign(SMA=X_train_scaled[:, 9])\n",
    "X_train= X_train.assign(STREND=X_train_scaled[:, 10])\n",
    "\n",
    "\n",
    "X_test_scaled=scl.transform(X_test)\n",
    "\n",
    "X_test= X_test.assign(Open=X_test_scaled[:, 0])\n",
    "X_test= X_test.assign(High=X_test_scaled[:, 1])\n",
    "X_test= X_test.assign(Low=X_test_scaled[:, 2])\n",
    "X_test= X_test.assign(Close=X_test_scaled[:, 3])\n",
    "X_test= X_test.assign(Volume=X_test_scaled[:, 4])\n",
    "X_test= X_test.assign(ADX=X_test_scaled[:, 5])\n",
    "X_test= X_test.assign(ATR=X_test_scaled[:, 6])\n",
    "X_test= X_test.assign(BBAND=X_test_scaled[:, 7])\n",
    "X_test= X_test.assign(RSI=X_test_scaled[:, 8])\n",
    "X_test= X_test.assign(SMA=X_test_scaled[:, 9])\n",
    "X_test= X_test.assign(STREND=X_test_scaled[:, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 8\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X and y into numpy arrays\n",
    "X_np = X_train.to_numpy(dtype=float)\n",
    "y_np = y_train.to_numpy(dtype=float)\n",
    "\n",
    "# Convert the numpy arrays into torch tensors\n",
    "X_tensor = torch.tensor(X_np, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_np, dtype=torch.float).unsqueeze(1)  # Adding an extra dimension to y to match input requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(11,20, batch_first = True)\n",
    "lin = nn.Linear(20,3)\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam([\n",
    "            {'params': lstm.parameters()},\n",
    "            {'params': lin.parameters()}\n",
    "        ], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.05626\n",
      "Epoch: 2, loss: 0.65146\n",
      "Epoch: 4, loss: 0.43511\n",
      "Epoch: 6, loss: 0.36505\n",
      "Epoch: 8, loss: 0.34025\n",
      "Epoch: 10, loss: 0.32988\n",
      "Epoch: 12, loss: 0.32502\n",
      "Epoch: 14, loss: 0.32251\n",
      "Epoch: 16, loss: 0.32110\n",
      "Epoch: 18, loss: 0.32027\n",
      "Epoch: 20, loss: 0.31974\n",
      "Epoch: 22, loss: 0.31939\n",
      "Epoch: 24, loss: 0.31915\n",
      "Epoch: 26, loss: 0.31898\n",
      "Epoch: 28, loss: 0.31886\n",
      "Epoch: 30, loss: 0.31876\n",
      "Epoch: 32, loss: 0.31869\n",
      "Epoch: 34, loss: 0.31864\n",
      "Epoch: 36, loss: 0.31859\n",
      "Epoch: 38, loss: 0.31856\n",
      "Epoch: 40, loss: 0.31853\n",
      "Epoch: 42, loss: 0.31851\n",
      "Epoch: 44, loss: 0.31849\n",
      "Epoch: 46, loss: 0.31847\n",
      "Epoch: 48, loss: 0.31846\n",
      "Epoch: 50, loss: 0.31844\n",
      "Epoch: 52, loss: 0.31843\n",
      "Epoch: 54, loss: 0.31843\n",
      "Epoch: 56, loss: 0.31842\n",
      "Epoch: 58, loss: 0.31841\n",
      "Epoch: 60, loss: 0.31840\n",
      "Epoch: 62, loss: 0.31840\n",
      "Epoch: 64, loss: 0.31839\n",
      "Epoch: 66, loss: 0.31839\n",
      "Epoch: 68, loss: 0.31838\n",
      "Epoch: 70, loss: 0.31838\n",
      "Epoch: 72, loss: 0.31837\n",
      "Epoch: 74, loss: 0.31837\n",
      "Epoch: 76, loss: 0.31837\n",
      "Epoch: 78, loss: 0.31836\n",
      "Epoch: 80, loss: 0.31836\n",
      "Epoch: 82, loss: 0.31836\n",
      "Epoch: 84, loss: 0.31835\n",
      "Epoch: 86, loss: 0.31835\n",
      "Epoch: 88, loss: 0.31835\n",
      "Epoch: 90, loss: 0.31834\n",
      "Epoch: 92, loss: 0.31834\n",
      "Epoch: 94, loss: 0.31834\n",
      "Epoch: 96, loss: 0.31833\n",
      "Epoch: 98, loss: 0.31833\n",
      "Epoch: 100, loss: 0.31833\n",
      "Epoch: 102, loss: 0.31832\n",
      "Epoch: 104, loss: 0.31832\n",
      "Epoch: 106, loss: 0.31832\n",
      "Epoch: 108, loss: 0.31831\n",
      "Epoch: 110, loss: 0.31831\n",
      "Epoch: 112, loss: 0.31831\n",
      "Epoch: 114, loss: 0.31831\n",
      "Epoch: 116, loss: 0.31830\n",
      "Epoch: 118, loss: 0.31830\n",
      "Epoch: 120, loss: 0.31830\n",
      "Epoch: 122, loss: 0.31829\n",
      "Epoch: 124, loss: 0.31829\n",
      "Epoch: 126, loss: 0.31829\n",
      "Epoch: 128, loss: 0.31829\n",
      "Epoch: 130, loss: 0.31828\n",
      "Epoch: 132, loss: 0.31828\n",
      "Epoch: 134, loss: 0.31828\n",
      "Epoch: 136, loss: 0.31828\n",
      "Epoch: 138, loss: 0.31827\n",
      "Epoch: 140, loss: 0.31827\n",
      "Epoch: 142, loss: 0.31827\n",
      "Epoch: 144, loss: 0.31827\n",
      "Epoch: 146, loss: 0.31826\n",
      "Epoch: 148, loss: 0.31826\n",
      "Epoch: 150, loss: 0.31826\n",
      "Epoch: 152, loss: 0.31826\n",
      "Epoch: 154, loss: 0.31825\n",
      "Epoch: 156, loss: 0.31825\n",
      "Epoch: 158, loss: 0.31825\n",
      "Epoch: 160, loss: 0.31825\n",
      "Epoch: 162, loss: 0.31824\n",
      "Epoch: 164, loss: 0.31824\n",
      "Epoch: 166, loss: 0.31824\n",
      "Epoch: 168, loss: 0.31824\n",
      "Epoch: 170, loss: 0.31824\n",
      "Epoch: 172, loss: 0.31823\n",
      "Epoch: 174, loss: 0.31823\n",
      "Epoch: 176, loss: 0.31823\n",
      "Epoch: 178, loss: 0.31823\n",
      "Epoch: 180, loss: 0.31823\n",
      "Epoch: 182, loss: 0.31822\n",
      "Epoch: 184, loss: 0.31822\n",
      "Epoch: 186, loss: 0.31822\n",
      "Epoch: 188, loss: 0.31822\n",
      "Epoch: 190, loss: 0.31822\n",
      "Epoch: 192, loss: 0.31821\n",
      "Epoch: 194, loss: 0.31821\n",
      "Epoch: 196, loss: 0.31821\n",
      "Epoch: 198, loss: 0.31821\n",
      "Epoch: 200, loss: 0.31821\n",
      "Epoch: 202, loss: 0.31820\n",
      "Epoch: 204, loss: 0.31820\n",
      "Epoch: 206, loss: 0.31820\n",
      "Epoch: 208, loss: 0.31820\n",
      "Epoch: 210, loss: 0.31820\n",
      "Epoch: 212, loss: 0.31820\n",
      "Epoch: 214, loss: 0.31819\n",
      "Epoch: 216, loss: 0.31819\n",
      "Epoch: 218, loss: 0.31819\n",
      "Epoch: 220, loss: 0.31819\n",
      "Epoch: 222, loss: 0.31819\n",
      "Epoch: 224, loss: 0.31819\n",
      "Epoch: 226, loss: 0.31818\n",
      "Epoch: 228, loss: 0.31818\n",
      "Epoch: 230, loss: 0.31818\n",
      "Epoch: 232, loss: 0.31818\n",
      "Epoch: 234, loss: 0.31818\n",
      "Epoch: 236, loss: 0.31818\n",
      "Epoch: 238, loss: 0.31818\n",
      "Epoch: 240, loss: 0.31817\n",
      "Epoch: 242, loss: 0.31817\n",
      "Epoch: 244, loss: 0.31817\n",
      "Epoch: 246, loss: 0.31817\n",
      "Epoch: 248, loss: 0.31817\n",
      "Epoch: 250, loss: 0.31817\n",
      "Epoch: 252, loss: 0.31817\n",
      "Epoch: 254, loss: 0.31816\n",
      "Epoch: 256, loss: 0.31816\n",
      "Epoch: 258, loss: 0.31816\n",
      "Epoch: 260, loss: 0.31816\n",
      "Epoch: 262, loss: 0.31816\n",
      "Epoch: 264, loss: 0.31816\n",
      "Epoch: 266, loss: 0.31816\n",
      "Epoch: 268, loss: 0.31816\n",
      "Epoch: 270, loss: 0.31815\n",
      "Epoch: 272, loss: 0.31815\n",
      "Epoch: 274, loss: 0.31815\n",
      "Epoch: 276, loss: 0.31815\n",
      "Epoch: 278, loss: 0.31815\n",
      "Epoch: 280, loss: 0.31815\n",
      "Epoch: 282, loss: 0.31815\n",
      "Epoch: 284, loss: 0.31815\n",
      "Epoch: 286, loss: 0.31815\n",
      "Epoch: 288, loss: 0.31814\n",
      "Epoch: 290, loss: 0.31814\n",
      "Epoch: 292, loss: 0.31814\n",
      "Epoch: 294, loss: 0.31814\n",
      "Epoch: 296, loss: 0.31814\n",
      "Epoch: 298, loss: 0.31814\n",
      "Epoch: 300, loss: 0.31814\n",
      "Epoch: 302, loss: 0.31814\n",
      "Epoch: 304, loss: 0.31814\n",
      "Epoch: 306, loss: 0.31813\n",
      "Epoch: 308, loss: 0.31813\n",
      "Epoch: 310, loss: 0.31813\n",
      "Epoch: 312, loss: 0.31813\n",
      "Epoch: 314, loss: 0.31813\n",
      "Epoch: 316, loss: 0.31813\n",
      "Epoch: 318, loss: 0.31813\n",
      "Epoch: 320, loss: 0.31813\n",
      "Epoch: 322, loss: 0.31813\n",
      "Epoch: 324, loss: 0.31813\n",
      "Epoch: 326, loss: 0.31813\n",
      "Epoch: 328, loss: 0.31812\n",
      "Epoch: 330, loss: 0.31812\n",
      "Epoch: 332, loss: 0.31812\n",
      "Epoch: 334, loss: 0.31812\n",
      "Epoch: 336, loss: 0.31812\n",
      "Epoch: 338, loss: 0.31812\n",
      "Epoch: 340, loss: 0.31812\n",
      "Epoch: 342, loss: 0.31812\n",
      "Epoch: 344, loss: 0.31812\n",
      "Epoch: 346, loss: 0.31812\n",
      "Epoch: 348, loss: 0.31812\n",
      "Epoch: 350, loss: 0.31812\n",
      "Epoch: 352, loss: 0.31811\n",
      "Epoch: 354, loss: 0.31811\n",
      "Epoch: 356, loss: 0.31811\n",
      "Epoch: 358, loss: 0.31811\n",
      "Epoch: 360, loss: 0.31811\n",
      "Epoch: 362, loss: 0.31811\n",
      "Epoch: 364, loss: 0.31811\n",
      "Epoch: 366, loss: 0.31811\n",
      "Epoch: 368, loss: 0.31811\n",
      "Epoch: 370, loss: 0.31811\n",
      "Epoch: 372, loss: 0.31811\n",
      "Epoch: 374, loss: 0.31811\n",
      "Epoch: 376, loss: 0.31811\n",
      "Epoch: 378, loss: 0.31810\n",
      "Epoch: 380, loss: 0.31810\n",
      "Epoch: 382, loss: 0.31810\n",
      "Epoch: 384, loss: 0.31810\n",
      "Epoch: 386, loss: 0.31810\n",
      "Epoch: 388, loss: 0.31810\n",
      "Epoch: 390, loss: 0.31810\n",
      "Epoch: 392, loss: 0.31810\n",
      "Epoch: 394, loss: 0.31810\n",
      "Epoch: 396, loss: 0.31810\n",
      "Epoch: 398, loss: 0.31810\n",
      "Epoch: 400, loss: 0.31810\n",
      "Epoch: 402, loss: 0.31810\n",
      "Epoch: 404, loss: 0.31810\n",
      "Epoch: 406, loss: 0.31810\n",
      "Epoch: 408, loss: 0.31810\n",
      "Epoch: 410, loss: 0.31809\n",
      "Epoch: 412, loss: 0.31809\n",
      "Epoch: 414, loss: 0.31809\n",
      "Epoch: 416, loss: 0.31809\n",
      "Epoch: 418, loss: 0.31809\n",
      "Epoch: 420, loss: 0.31809\n",
      "Epoch: 422, loss: 0.31809\n",
      "Epoch: 424, loss: 0.31809\n",
      "Epoch: 426, loss: 0.31809\n",
      "Epoch: 428, loss: 0.31809\n",
      "Epoch: 430, loss: 0.31809\n",
      "Epoch: 432, loss: 0.31809\n",
      "Epoch: 434, loss: 0.31809\n",
      "Epoch: 436, loss: 0.31809\n",
      "Epoch: 438, loss: 0.31809\n",
      "Epoch: 440, loss: 0.31809\n",
      "Epoch: 442, loss: 0.31809\n",
      "Epoch: 444, loss: 0.31808\n",
      "Epoch: 446, loss: 0.31808\n",
      "Epoch: 448, loss: 0.31808\n",
      "Epoch: 450, loss: 0.31808\n",
      "Epoch: 452, loss: 0.31808\n",
      "Epoch: 454, loss: 0.31808\n",
      "Epoch: 456, loss: 0.31808\n",
      "Epoch: 458, loss: 0.31808\n",
      "Epoch: 460, loss: 0.31808\n",
      "Epoch: 462, loss: 0.31808\n",
      "Epoch: 464, loss: 0.31808\n",
      "Epoch: 466, loss: 0.31808\n",
      "Epoch: 468, loss: 0.31808\n",
      "Epoch: 470, loss: 0.31808\n",
      "Epoch: 472, loss: 0.31808\n",
      "Epoch: 474, loss: 0.31808\n",
      "Epoch: 476, loss: 0.31808\n",
      "Epoch: 478, loss: 0.31808\n",
      "Epoch: 480, loss: 0.31808\n",
      "Epoch: 482, loss: 0.31808\n",
      "Epoch: 484, loss: 0.31808\n",
      "Epoch: 486, loss: 0.31807\n",
      "Epoch: 488, loss: 0.31807\n",
      "Epoch: 490, loss: 0.31807\n",
      "Epoch: 492, loss: 0.31807\n",
      "Epoch: 494, loss: 0.31807\n",
      "Epoch: 496, loss: 0.31807\n",
      "Epoch: 498, loss: 0.31807\n",
      "Epoch: 500, loss: 0.31807\n",
      "Epoch: 502, loss: 0.31807\n",
      "Epoch: 504, loss: 0.31807\n",
      "Epoch: 506, loss: 0.31807\n",
      "Epoch: 508, loss: 0.31807\n",
      "Epoch: 510, loss: 0.31807\n",
      "Epoch: 512, loss: 0.31807\n",
      "Epoch: 514, loss: 0.31807\n",
      "Epoch: 516, loss: 0.31807\n",
      "Epoch: 518, loss: 0.31807\n",
      "Epoch: 520, loss: 0.31807\n",
      "Epoch: 522, loss: 0.31807\n",
      "Epoch: 524, loss: 0.31807\n",
      "Epoch: 526, loss: 0.31807\n",
      "Epoch: 528, loss: 0.31807\n",
      "Epoch: 530, loss: 0.31807\n",
      "Epoch: 532, loss: 0.31807\n",
      "Epoch: 534, loss: 0.31807\n",
      "Epoch: 536, loss: 0.31807\n",
      "Epoch: 538, loss: 0.31806\n",
      "Epoch: 540, loss: 0.31806\n",
      "Epoch: 542, loss: 0.31806\n",
      "Epoch: 544, loss: 0.31806\n",
      "Epoch: 546, loss: 0.31806\n",
      "Epoch: 548, loss: 0.31806\n",
      "Epoch: 550, loss: 0.31806\n",
      "Epoch: 552, loss: 0.31806\n",
      "Epoch: 554, loss: 0.31806\n",
      "Epoch: 556, loss: 0.31806\n",
      "Epoch: 558, loss: 0.31806\n",
      "Epoch: 560, loss: 0.31806\n",
      "Epoch: 562, loss: 0.31806\n",
      "Epoch: 564, loss: 0.31806\n",
      "Epoch: 566, loss: 0.31806\n",
      "Epoch: 568, loss: 0.31806\n",
      "Epoch: 570, loss: 0.31806\n",
      "Epoch: 572, loss: 0.31806\n",
      "Epoch: 574, loss: 0.31806\n",
      "Epoch: 576, loss: 0.31806\n",
      "Epoch: 578, loss: 0.31806\n",
      "Epoch: 580, loss: 0.31806\n",
      "Epoch: 582, loss: 0.31806\n",
      "Epoch: 584, loss: 0.31806\n",
      "Epoch: 586, loss: 0.31806\n",
      "Epoch: 588, loss: 0.31806\n",
      "Epoch: 590, loss: 0.31806\n",
      "Epoch: 592, loss: 0.31806\n",
      "Epoch: 594, loss: 0.31806\n",
      "Epoch: 596, loss: 0.31806\n",
      "Epoch: 598, loss: 0.31806\n",
      "Epoch: 600, loss: 0.31805\n",
      "Epoch: 602, loss: 0.31805\n",
      "Epoch: 604, loss: 0.31805\n",
      "Epoch: 606, loss: 0.31805\n",
      "Epoch: 608, loss: 0.31805\n",
      "Epoch: 610, loss: 0.31805\n",
      "Epoch: 612, loss: 0.31805\n",
      "Epoch: 614, loss: 0.31805\n",
      "Epoch: 616, loss: 0.31805\n",
      "Epoch: 618, loss: 0.31805\n",
      "Epoch: 620, loss: 0.31805\n",
      "Epoch: 622, loss: 0.31805\n",
      "Epoch: 624, loss: 0.31805\n",
      "Epoch: 626, loss: 0.31805\n",
      "Epoch: 628, loss: 0.31805\n",
      "Epoch: 630, loss: 0.31805\n",
      "Epoch: 632, loss: 0.31805\n",
      "Epoch: 634, loss: 0.31805\n",
      "Epoch: 636, loss: 0.31805\n",
      "Epoch: 638, loss: 0.31805\n",
      "Epoch: 640, loss: 0.31805\n",
      "Epoch: 642, loss: 0.31805\n",
      "Epoch: 644, loss: 0.31805\n",
      "Epoch: 646, loss: 0.31805\n",
      "Epoch: 648, loss: 0.31805\n",
      "Epoch: 650, loss: 0.31805\n",
      "Epoch: 652, loss: 0.31805\n",
      "Epoch: 654, loss: 0.31805\n",
      "Epoch: 656, loss: 0.31805\n",
      "Epoch: 658, loss: 0.31805\n",
      "Epoch: 660, loss: 0.31805\n",
      "Epoch: 662, loss: 0.31805\n",
      "Epoch: 664, loss: 0.31805\n",
      "Epoch: 666, loss: 0.31805\n",
      "Epoch: 668, loss: 0.31805\n",
      "Epoch: 670, loss: 0.31805\n",
      "Epoch: 672, loss: 0.31805\n",
      "Epoch: 674, loss: 0.31805\n",
      "Epoch: 676, loss: 0.31805\n",
      "Epoch: 678, loss: 0.31805\n",
      "Epoch: 680, loss: 0.31805\n",
      "Epoch: 682, loss: 0.31804\n",
      "Epoch: 684, loss: 0.31804\n",
      "Epoch: 686, loss: 0.31804\n",
      "Epoch: 688, loss: 0.31804\n",
      "Epoch: 690, loss: 0.31804\n",
      "Epoch: 692, loss: 0.31804\n",
      "Epoch: 694, loss: 0.31804\n",
      "Epoch: 696, loss: 0.31804\n",
      "Epoch: 698, loss: 0.31804\n",
      "Epoch: 700, loss: 0.31804\n",
      "Epoch: 702, loss: 0.31804\n",
      "Epoch: 704, loss: 0.31804\n",
      "Epoch: 706, loss: 0.31804\n",
      "Epoch: 708, loss: 0.31804\n",
      "Epoch: 710, loss: 0.31804\n",
      "Epoch: 712, loss: 0.31804\n",
      "Epoch: 714, loss: 0.31804\n",
      "Epoch: 716, loss: 0.31804\n",
      "Epoch: 718, loss: 0.31804\n",
      "Epoch: 720, loss: 0.31804\n",
      "Epoch: 722, loss: 0.31804\n",
      "Epoch: 724, loss: 0.31804\n",
      "Epoch: 726, loss: 0.31804\n",
      "Epoch: 728, loss: 0.31804\n",
      "Epoch: 730, loss: 0.31804\n",
      "Epoch: 732, loss: 0.31804\n",
      "Epoch: 734, loss: 0.31804\n",
      "Epoch: 736, loss: 0.31804\n",
      "Epoch: 738, loss: 0.31804\n",
      "Epoch: 740, loss: 0.31804\n",
      "Epoch: 742, loss: 0.31804\n",
      "Epoch: 744, loss: 0.31804\n",
      "Epoch: 746, loss: 0.31804\n",
      "Epoch: 748, loss: 0.31804\n",
      "Epoch: 750, loss: 0.31804\n",
      "Epoch: 752, loss: 0.31804\n",
      "Epoch: 754, loss: 0.31804\n",
      "Epoch: 756, loss: 0.31804\n",
      "Epoch: 758, loss: 0.31804\n",
      "Epoch: 760, loss: 0.31804\n",
      "Epoch: 762, loss: 0.31804\n",
      "Epoch: 764, loss: 0.31804\n",
      "Epoch: 766, loss: 0.31804\n",
      "Epoch: 768, loss: 0.31804\n",
      "Epoch: 770, loss: 0.31804\n",
      "Epoch: 772, loss: 0.31804\n",
      "Epoch: 774, loss: 0.31804\n",
      "Epoch: 776, loss: 0.31804\n",
      "Epoch: 778, loss: 0.31804\n",
      "Epoch: 780, loss: 0.31804\n",
      "Epoch: 782, loss: 0.31804\n",
      "Epoch: 784, loss: 0.31804\n",
      "Epoch: 786, loss: 0.31804\n",
      "Epoch: 788, loss: 0.31804\n",
      "Epoch: 790, loss: 0.31803\n",
      "Epoch: 792, loss: 0.31803\n",
      "Epoch: 794, loss: 0.31803\n",
      "Epoch: 796, loss: 0.31803\n",
      "Epoch: 798, loss: 0.31803\n",
      "Epoch: 800, loss: 0.31803\n",
      "Epoch: 802, loss: 0.31803\n",
      "Epoch: 804, loss: 0.31803\n",
      "Epoch: 806, loss: 0.31803\n",
      "Epoch: 808, loss: 0.31803\n",
      "Epoch: 810, loss: 0.31803\n",
      "Epoch: 812, loss: 0.31803\n",
      "Epoch: 814, loss: 0.31803\n",
      "Epoch: 816, loss: 0.31803\n",
      "Epoch: 818, loss: 0.31803\n",
      "Epoch: 820, loss: 0.31803\n",
      "Epoch: 822, loss: 0.31803\n",
      "Epoch: 824, loss: 0.31803\n",
      "Epoch: 826, loss: 0.31803\n",
      "Epoch: 828, loss: 0.31803\n",
      "Epoch: 830, loss: 0.31803\n",
      "Epoch: 832, loss: 0.31803\n",
      "Epoch: 834, loss: 0.31803\n",
      "Epoch: 836, loss: 0.31803\n",
      "Epoch: 838, loss: 0.31803\n",
      "Epoch: 840, loss: 0.31803\n",
      "Epoch: 842, loss: 0.31803\n",
      "Epoch: 844, loss: 0.31803\n",
      "Epoch: 846, loss: 0.31803\n",
      "Epoch: 848, loss: 0.31803\n",
      "Epoch: 850, loss: 0.31803\n",
      "Epoch: 852, loss: 0.31803\n",
      "Epoch: 854, loss: 0.31803\n",
      "Epoch: 856, loss: 0.31803\n",
      "Epoch: 858, loss: 0.31803\n",
      "Epoch: 860, loss: 0.31803\n",
      "Epoch: 862, loss: 0.31803\n",
      "Epoch: 864, loss: 0.31803\n",
      "Epoch: 866, loss: 0.31803\n",
      "Epoch: 868, loss: 0.31803\n",
      "Epoch: 870, loss: 0.31803\n",
      "Epoch: 872, loss: 0.31803\n",
      "Epoch: 874, loss: 0.31803\n",
      "Epoch: 876, loss: 0.31803\n",
      "Epoch: 878, loss: 0.31803\n",
      "Epoch: 880, loss: 0.31803\n",
      "Epoch: 882, loss: 0.31803\n",
      "Epoch: 884, loss: 0.31803\n",
      "Epoch: 886, loss: 0.31803\n",
      "Epoch: 888, loss: 0.31803\n",
      "Epoch: 890, loss: 0.31803\n",
      "Epoch: 892, loss: 0.31803\n",
      "Epoch: 894, loss: 0.31803\n",
      "Epoch: 896, loss: 0.31803\n",
      "Epoch: 898, loss: 0.31803\n",
      "Epoch: 900, loss: 0.31803\n",
      "Epoch: 902, loss: 0.31803\n",
      "Epoch: 904, loss: 0.31803\n",
      "Epoch: 906, loss: 0.31803\n",
      "Epoch: 908, loss: 0.31803\n",
      "Epoch: 910, loss: 0.31803\n",
      "Epoch: 912, loss: 0.31803\n",
      "Epoch: 914, loss: 0.31803\n",
      "Epoch: 916, loss: 0.31803\n",
      "Epoch: 918, loss: 0.31803\n",
      "Epoch: 920, loss: 0.31803\n",
      "Epoch: 922, loss: 0.31803\n",
      "Epoch: 924, loss: 0.31803\n",
      "Epoch: 926, loss: 0.31803\n",
      "Epoch: 928, loss: 0.31803\n",
      "Epoch: 930, loss: 0.31803\n",
      "Epoch: 932, loss: 0.31803\n",
      "Epoch: 934, loss: 0.31803\n",
      "Epoch: 936, loss: 0.31803\n",
      "Epoch: 938, loss: 0.31803\n",
      "Epoch: 940, loss: 0.31803\n",
      "Epoch: 942, loss: 0.31803\n",
      "Epoch: 944, loss: 0.31803\n",
      "Epoch: 946, loss: 0.31803\n",
      "Epoch: 948, loss: 0.31802\n",
      "Epoch: 950, loss: 0.31802\n",
      "Epoch: 952, loss: 0.31802\n",
      "Epoch: 954, loss: 0.31802\n",
      "Epoch: 956, loss: 0.31802\n",
      "Epoch: 958, loss: 0.31802\n",
      "Epoch: 960, loss: 0.31802\n",
      "Epoch: 962, loss: 0.31802\n",
      "Epoch: 964, loss: 0.31802\n",
      "Epoch: 966, loss: 0.31802\n",
      "Epoch: 968, loss: 0.31802\n",
      "Epoch: 970, loss: 0.31802\n",
      "Epoch: 972, loss: 0.31802\n",
      "Epoch: 974, loss: 0.31802\n",
      "Epoch: 976, loss: 0.31802\n",
      "Epoch: 978, loss: 0.31802\n",
      "Epoch: 980, loss: 0.31802\n",
      "Epoch: 982, loss: 0.31802\n",
      "Epoch: 984, loss: 0.31802\n",
      "Epoch: 986, loss: 0.31802\n",
      "Epoch: 988, loss: 0.31802\n",
      "Epoch: 990, loss: 0.31802\n",
      "Epoch: 992, loss: 0.31802\n",
      "Epoch: 994, loss: 0.31802\n",
      "Epoch: 996, loss: 0.31802\n",
      "Epoch: 998, loss: 0.31802\n",
      "Epoch: 1000, loss: 0.31802\n",
      "Epoch: 1002, loss: 0.31802\n",
      "Epoch: 1004, loss: 0.31802\n",
      "Epoch: 1006, loss: 0.31802\n",
      "Epoch: 1008, loss: 0.31802\n",
      "Epoch: 1010, loss: 0.31802\n",
      "Epoch: 1012, loss: 0.31802\n",
      "Epoch: 1014, loss: 0.31802\n",
      "Epoch: 1016, loss: 0.31802\n",
      "Epoch: 1018, loss: 0.31802\n",
      "Epoch: 1020, loss: 0.31802\n",
      "Epoch: 1022, loss: 0.31802\n",
      "Epoch: 1024, loss: 0.31802\n",
      "Epoch: 1026, loss: 0.31802\n",
      "Epoch: 1028, loss: 0.31802\n",
      "Epoch: 1030, loss: 0.31802\n",
      "Epoch: 1032, loss: 0.31802\n",
      "Epoch: 1034, loss: 0.31802\n",
      "Epoch: 1036, loss: 0.31802\n",
      "Epoch: 1038, loss: 0.31802\n",
      "Epoch: 1040, loss: 0.31802\n",
      "Epoch: 1042, loss: 0.31802\n",
      "Epoch: 1044, loss: 0.31802\n",
      "Epoch: 1046, loss: 0.31802\n",
      "Epoch: 1048, loss: 0.31802\n",
      "Epoch: 1050, loss: 0.31802\n",
      "Epoch: 1052, loss: 0.31802\n",
      "Epoch: 1054, loss: 0.31802\n",
      "Epoch: 1056, loss: 0.31802\n",
      "Epoch: 1058, loss: 0.31802\n",
      "Epoch: 1060, loss: 0.31802\n",
      "Epoch: 1062, loss: 0.31802\n",
      "Epoch: 1064, loss: 0.31802\n",
      "Epoch: 1066, loss: 0.31802\n",
      "Epoch: 1068, loss: 0.31802\n",
      "Epoch: 1070, loss: 0.31802\n",
      "Epoch: 1072, loss: 0.31802\n",
      "Epoch: 1074, loss: 0.31802\n",
      "Epoch: 1076, loss: 0.31802\n",
      "Epoch: 1078, loss: 0.31802\n",
      "Epoch: 1080, loss: 0.31802\n",
      "Epoch: 1082, loss: 0.31802\n",
      "Epoch: 1084, loss: 0.31802\n",
      "Epoch: 1086, loss: 0.31802\n",
      "Epoch: 1088, loss: 0.31802\n",
      "Epoch: 1090, loss: 0.31802\n",
      "Epoch: 1092, loss: 0.31802\n",
      "Epoch: 1094, loss: 0.31802\n",
      "Epoch: 1096, loss: 0.31802\n",
      "Epoch: 1098, loss: 0.31802\n",
      "Epoch: 1100, loss: 0.31802\n",
      "Epoch: 1102, loss: 0.31802\n",
      "Epoch: 1104, loss: 0.31802\n",
      "Epoch: 1106, loss: 0.31802\n",
      "Epoch: 1108, loss: 0.31802\n",
      "Epoch: 1110, loss: 0.31802\n",
      "Epoch: 1112, loss: 0.31802\n",
      "Epoch: 1114, loss: 0.31802\n",
      "Epoch: 1116, loss: 0.31802\n",
      "Epoch: 1118, loss: 0.31802\n",
      "Epoch: 1120, loss: 0.31802\n",
      "Epoch: 1122, loss: 0.31802\n",
      "Epoch: 1124, loss: 0.31802\n",
      "Epoch: 1126, loss: 0.31802\n",
      "Epoch: 1128, loss: 0.31802\n",
      "Epoch: 1130, loss: 0.31802\n",
      "Epoch: 1132, loss: 0.31802\n",
      "Epoch: 1134, loss: 0.31802\n",
      "Epoch: 1136, loss: 0.31802\n",
      "Epoch: 1138, loss: 0.31802\n",
      "Epoch: 1140, loss: 0.31802\n",
      "Epoch: 1142, loss: 0.31802\n",
      "Epoch: 1144, loss: 0.31802\n",
      "Epoch: 1146, loss: 0.31802\n",
      "Epoch: 1148, loss: 0.31802\n",
      "Epoch: 1150, loss: 0.31802\n",
      "Epoch: 1152, loss: 0.31802\n",
      "Epoch: 1154, loss: 0.31802\n",
      "Epoch: 1156, loss: 0.31802\n",
      "Epoch: 1158, loss: 0.31802\n",
      "Epoch: 1160, loss: 0.31802\n",
      "Epoch: 1162, loss: 0.31802\n",
      "Epoch: 1164, loss: 0.31802\n",
      "Epoch: 1166, loss: 0.31802\n",
      "Epoch: 1168, loss: 0.31802\n",
      "Epoch: 1170, loss: 0.31802\n",
      "Epoch: 1172, loss: 0.31802\n",
      "Epoch: 1174, loss: 0.31802\n",
      "Epoch: 1176, loss: 0.31802\n",
      "Epoch: 1178, loss: 0.31802\n",
      "Epoch: 1180, loss: 0.31802\n",
      "Epoch: 1182, loss: 0.31802\n",
      "Epoch: 1184, loss: 0.31802\n",
      "Epoch: 1186, loss: 0.31802\n",
      "Epoch: 1188, loss: 0.31802\n",
      "Epoch: 1190, loss: 0.31802\n",
      "Epoch: 1192, loss: 0.31802\n",
      "Epoch: 1194, loss: 0.31802\n",
      "Epoch: 1196, loss: 0.31802\n",
      "Epoch: 1198, loss: 0.31802\n",
      "Epoch: 1200, loss: 0.31802\n",
      "Epoch: 1202, loss: 0.31802\n",
      "Epoch: 1204, loss: 0.31802\n",
      "Epoch: 1206, loss: 0.31801\n",
      "Epoch: 1208, loss: 0.31801\n",
      "Epoch: 1210, loss: 0.31801\n",
      "Epoch: 1212, loss: 0.31801\n",
      "Epoch: 1214, loss: 0.31801\n",
      "Epoch: 1216, loss: 0.31801\n",
      "Epoch: 1218, loss: 0.31801\n",
      "Epoch: 1220, loss: 0.31801\n",
      "Epoch: 1222, loss: 0.31801\n",
      "Epoch: 1224, loss: 0.31801\n",
      "Epoch: 1226, loss: 0.31801\n",
      "Epoch: 1228, loss: 0.31801\n",
      "Epoch: 1230, loss: 0.31801\n",
      "Epoch: 1232, loss: 0.31801\n",
      "Epoch: 1234, loss: 0.31801\n",
      "Epoch: 1236, loss: 0.31801\n",
      "Epoch: 1238, loss: 0.31801\n",
      "Epoch: 1240, loss: 0.31801\n",
      "Epoch: 1242, loss: 0.31801\n",
      "Epoch: 1244, loss: 0.31801\n",
      "Epoch: 1246, loss: 0.31801\n",
      "Epoch: 1248, loss: 0.31801\n",
      "Epoch: 1250, loss: 0.31801\n",
      "Epoch: 1252, loss: 0.31801\n",
      "Epoch: 1254, loss: 0.31801\n",
      "Epoch: 1256, loss: 0.31801\n",
      "Epoch: 1258, loss: 0.31801\n",
      "Epoch: 1260, loss: 0.31801\n",
      "Epoch: 1262, loss: 0.31801\n",
      "Epoch: 1264, loss: 0.31801\n",
      "Epoch: 1266, loss: 0.31801\n",
      "Epoch: 1268, loss: 0.31801\n",
      "Epoch: 1270, loss: 0.31801\n",
      "Epoch: 1272, loss: 0.31801\n",
      "Epoch: 1274, loss: 0.31801\n",
      "Epoch: 1276, loss: 0.31801\n",
      "Epoch: 1278, loss: 0.31801\n",
      "Epoch: 1280, loss: 0.31801\n",
      "Epoch: 1282, loss: 0.31801\n",
      "Epoch: 1284, loss: 0.31801\n",
      "Epoch: 1286, loss: 0.31801\n",
      "Epoch: 1288, loss: 0.31801\n",
      "Epoch: 1290, loss: 0.31801\n",
      "Epoch: 1292, loss: 0.31801\n",
      "Epoch: 1294, loss: 0.31801\n",
      "Epoch: 1296, loss: 0.31801\n",
      "Epoch: 1298, loss: 0.31801\n",
      "Epoch: 1300, loss: 0.31801\n",
      "Epoch: 1302, loss: 0.31801\n",
      "Epoch: 1304, loss: 0.31801\n",
      "Epoch: 1306, loss: 0.31801\n",
      "Epoch: 1308, loss: 0.31801\n",
      "Epoch: 1310, loss: 0.31801\n",
      "Epoch: 1312, loss: 0.31801\n",
      "Epoch: 1314, loss: 0.31801\n",
      "Epoch: 1316, loss: 0.31801\n",
      "Epoch: 1318, loss: 0.31801\n",
      "Epoch: 1320, loss: 0.31801\n",
      "Epoch: 1322, loss: 0.31801\n",
      "Epoch: 1324, loss: 0.31801\n",
      "Epoch: 1326, loss: 0.31801\n",
      "Epoch: 1328, loss: 0.31801\n",
      "Epoch: 1330, loss: 0.31801\n",
      "Epoch: 1332, loss: 0.31801\n",
      "Epoch: 1334, loss: 0.31801\n",
      "Epoch: 1336, loss: 0.31801\n",
      "Epoch: 1338, loss: 0.31801\n",
      "Epoch: 1340, loss: 0.31801\n",
      "Epoch: 1342, loss: 0.31801\n",
      "Epoch: 1344, loss: 0.31801\n",
      "Epoch: 1346, loss: 0.31801\n",
      "Epoch: 1348, loss: 0.31801\n",
      "Epoch: 1350, loss: 0.31801\n",
      "Epoch: 1352, loss: 0.31801\n",
      "Epoch: 1354, loss: 0.31801\n",
      "Epoch: 1356, loss: 0.31801\n",
      "Epoch: 1358, loss: 0.31801\n",
      "Epoch: 1360, loss: 0.31801\n",
      "Epoch: 1362, loss: 0.31801\n",
      "Epoch: 1364, loss: 0.31801\n",
      "Epoch: 1366, loss: 0.31801\n",
      "Epoch: 1368, loss: 0.31801\n",
      "Epoch: 1370, loss: 0.31801\n",
      "Epoch: 1372, loss: 0.31801\n",
      "Epoch: 1374, loss: 0.31801\n",
      "Epoch: 1376, loss: 0.31801\n",
      "Epoch: 1378, loss: 0.31801\n",
      "Epoch: 1380, loss: 0.31801\n",
      "Epoch: 1382, loss: 0.31801\n",
      "Epoch: 1384, loss: 0.31801\n",
      "Epoch: 1386, loss: 0.31801\n",
      "Epoch: 1388, loss: 0.31801\n",
      "Epoch: 1390, loss: 0.31801\n",
      "Epoch: 1392, loss: 0.31801\n",
      "Epoch: 1394, loss: 0.31801\n",
      "Epoch: 1396, loss: 0.31801\n",
      "Epoch: 1398, loss: 0.31801\n",
      "Epoch: 1400, loss: 0.31801\n",
      "Epoch: 1402, loss: 0.31801\n",
      "Epoch: 1404, loss: 0.31801\n",
      "Epoch: 1406, loss: 0.31801\n",
      "Epoch: 1408, loss: 0.31801\n",
      "Epoch: 1410, loss: 0.31801\n",
      "Epoch: 1412, loss: 0.31801\n",
      "Epoch: 1414, loss: 0.31801\n",
      "Epoch: 1416, loss: 0.31801\n",
      "Epoch: 1418, loss: 0.31801\n",
      "Epoch: 1420, loss: 0.31801\n",
      "Epoch: 1422, loss: 0.31801\n",
      "Epoch: 1424, loss: 0.31801\n",
      "Epoch: 1426, loss: 0.31801\n",
      "Epoch: 1428, loss: 0.31801\n",
      "Epoch: 1430, loss: 0.31801\n",
      "Epoch: 1432, loss: 0.31801\n",
      "Epoch: 1434, loss: 0.31801\n",
      "Epoch: 1436, loss: 0.31801\n",
      "Epoch: 1438, loss: 0.31801\n",
      "Epoch: 1440, loss: 0.31801\n",
      "Epoch: 1442, loss: 0.31801\n",
      "Epoch: 1444, loss: 0.31801\n",
      "Epoch: 1446, loss: 0.31801\n",
      "Epoch: 1448, loss: 0.31801\n",
      "Epoch: 1450, loss: 0.31801\n",
      "Epoch: 1452, loss: 0.31801\n",
      "Epoch: 1454, loss: 0.31801\n",
      "Epoch: 1456, loss: 0.31801\n",
      "Epoch: 1458, loss: 0.31801\n",
      "Epoch: 1460, loss: 0.31801\n",
      "Epoch: 1462, loss: 0.31801\n",
      "Epoch: 1464, loss: 0.31801\n",
      "Epoch: 1466, loss: 0.31801\n",
      "Epoch: 1468, loss: 0.31801\n",
      "Epoch: 1470, loss: 0.31801\n",
      "Epoch: 1472, loss: 0.31801\n",
      "Epoch: 1474, loss: 0.31801\n",
      "Epoch: 1476, loss: 0.31801\n",
      "Epoch: 1478, loss: 0.31801\n",
      "Epoch: 1480, loss: 0.31801\n",
      "Epoch: 1482, loss: 0.31801\n",
      "Epoch: 1484, loss: 0.31801\n",
      "Epoch: 1486, loss: 0.31801\n",
      "Epoch: 1488, loss: 0.31801\n",
      "Epoch: 1490, loss: 0.31801\n",
      "Epoch: 1492, loss: 0.31801\n",
      "Epoch: 1494, loss: 0.31801\n",
      "Epoch: 1496, loss: 0.31801\n",
      "Epoch: 1498, loss: 0.31801\n",
      "Epoch: 1500, loss: 0.31801\n",
      "Epoch: 1502, loss: 0.31801\n",
      "Epoch: 1504, loss: 0.31801\n",
      "Epoch: 1506, loss: 0.31801\n",
      "Epoch: 1508, loss: 0.31801\n",
      "Epoch: 1510, loss: 0.31801\n",
      "Epoch: 1512, loss: 0.31801\n",
      "Epoch: 1514, loss: 0.31801\n",
      "Epoch: 1516, loss: 0.31801\n",
      "Epoch: 1518, loss: 0.31801\n",
      "Epoch: 1520, loss: 0.31801\n",
      "Epoch: 1522, loss: 0.31801\n",
      "Epoch: 1524, loss: 0.31801\n",
      "Epoch: 1526, loss: 0.31801\n",
      "Epoch: 1528, loss: 0.31801\n",
      "Epoch: 1530, loss: 0.31801\n",
      "Epoch: 1532, loss: 0.31801\n",
      "Epoch: 1534, loss: 0.31801\n",
      "Epoch: 1536, loss: 0.31801\n",
      "Epoch: 1538, loss: 0.31801\n",
      "Epoch: 1540, loss: 0.31801\n",
      "Epoch: 1542, loss: 0.31801\n",
      "Epoch: 1544, loss: 0.31801\n",
      "Epoch: 1546, loss: 0.31801\n",
      "Epoch: 1548, loss: 0.31801\n",
      "Epoch: 1550, loss: 0.31801\n",
      "Epoch: 1552, loss: 0.31801\n",
      "Epoch: 1554, loss: 0.31801\n",
      "Epoch: 1556, loss: 0.31801\n",
      "Epoch: 1558, loss: 0.31801\n",
      "Epoch: 1560, loss: 0.31801\n",
      "Epoch: 1562, loss: 0.31801\n",
      "Epoch: 1564, loss: 0.31801\n",
      "Epoch: 1566, loss: 0.31801\n",
      "Epoch: 1568, loss: 0.31801\n",
      "Epoch: 1570, loss: 0.31801\n",
      "Epoch: 1572, loss: 0.31801\n",
      "Epoch: 1574, loss: 0.31801\n",
      "Epoch: 1576, loss: 0.31801\n",
      "Epoch: 1578, loss: 0.31801\n",
      "Epoch: 1580, loss: 0.31801\n",
      "Epoch: 1582, loss: 0.31801\n",
      "Epoch: 1584, loss: 0.31801\n",
      "Epoch: 1586, loss: 0.31801\n",
      "Epoch: 1588, loss: 0.31801\n",
      "Epoch: 1590, loss: 0.31801\n",
      "Epoch: 1592, loss: 0.31801\n",
      "Epoch: 1594, loss: 0.31801\n",
      "Epoch: 1596, loss: 0.31801\n",
      "Epoch: 1598, loss: 0.31801\n",
      "Epoch: 1600, loss: 0.31801\n",
      "Epoch: 1602, loss: 0.31801\n",
      "Epoch: 1604, loss: 0.31801\n",
      "Epoch: 1606, loss: 0.31801\n",
      "Epoch: 1608, loss: 0.31801\n",
      "Epoch: 1610, loss: 0.31801\n",
      "Epoch: 1612, loss: 0.31801\n",
      "Epoch: 1614, loss: 0.31801\n",
      "Epoch: 1616, loss: 0.31801\n",
      "Epoch: 1618, loss: 0.31801\n",
      "Epoch: 1620, loss: 0.31801\n",
      "Epoch: 1622, loss: 0.31801\n",
      "Epoch: 1624, loss: 0.31801\n",
      "Epoch: 1626, loss: 0.31801\n",
      "Epoch: 1628, loss: 0.31801\n",
      "Epoch: 1630, loss: 0.31801\n",
      "Epoch: 1632, loss: 0.31801\n",
      "Epoch: 1634, loss: 0.31801\n",
      "Epoch: 1636, loss: 0.31801\n",
      "Epoch: 1638, loss: 0.31801\n",
      "Epoch: 1640, loss: 0.31801\n",
      "Epoch: 1642, loss: 0.31801\n",
      "Epoch: 1644, loss: 0.31801\n",
      "Epoch: 1646, loss: 0.31801\n",
      "Epoch: 1648, loss: 0.31801\n",
      "Epoch: 1650, loss: 0.31801\n",
      "Epoch: 1652, loss: 0.31801\n",
      "Epoch: 1654, loss: 0.31801\n",
      "Epoch: 1656, loss: 0.31801\n",
      "Epoch: 1658, loss: 0.31801\n",
      "Epoch: 1660, loss: 0.31801\n",
      "Epoch: 1662, loss: 0.31801\n",
      "Epoch: 1664, loss: 0.31801\n",
      "Epoch: 1666, loss: 0.31801\n",
      "Epoch: 1668, loss: 0.31801\n",
      "Epoch: 1670, loss: 0.31801\n",
      "Epoch: 1672, loss: 0.31801\n",
      "Epoch: 1674, loss: 0.31801\n",
      "Epoch: 1676, loss: 0.31801\n",
      "Epoch: 1678, loss: 0.31801\n",
      "Epoch: 1680, loss: 0.31801\n",
      "Epoch: 1682, loss: 0.31801\n",
      "Epoch: 1684, loss: 0.31801\n",
      "Epoch: 1686, loss: 0.31801\n",
      "Epoch: 1688, loss: 0.31801\n",
      "Epoch: 1690, loss: 0.31801\n",
      "Epoch: 1692, loss: 0.31801\n",
      "Epoch: 1694, loss: 0.31801\n",
      "Epoch: 1696, loss: 0.31801\n",
      "Epoch: 1698, loss: 0.31801\n",
      "Epoch: 1700, loss: 0.31801\n",
      "Epoch: 1702, loss: 0.31801\n",
      "Epoch: 1704, loss: 0.31801\n",
      "Epoch: 1706, loss: 0.31801\n",
      "Epoch: 1708, loss: 0.31801\n",
      "Epoch: 1710, loss: 0.31801\n",
      "Epoch: 1712, loss: 0.31801\n",
      "Epoch: 1714, loss: 0.31801\n",
      "Epoch: 1716, loss: 0.31801\n",
      "Epoch: 1718, loss: 0.31801\n",
      "Epoch: 1720, loss: 0.31801\n",
      "Epoch: 1722, loss: 0.31801\n",
      "Epoch: 1724, loss: 0.31801\n",
      "Epoch: 1726, loss: 0.31801\n",
      "Epoch: 1728, loss: 0.31801\n",
      "Epoch: 1730, loss: 0.31801\n",
      "Epoch: 1732, loss: 0.31801\n",
      "Epoch: 1734, loss: 0.31801\n",
      "Epoch: 1736, loss: 0.31800\n",
      "Epoch: 1738, loss: 0.31800\n",
      "Epoch: 1740, loss: 0.31800\n",
      "Epoch: 1742, loss: 0.31800\n",
      "Epoch: 1744, loss: 0.31800\n",
      "Epoch: 1746, loss: 0.31800\n",
      "Epoch: 1748, loss: 0.31800\n",
      "Epoch: 1750, loss: 0.31800\n",
      "Epoch: 1752, loss: 0.31800\n",
      "Epoch: 1754, loss: 0.31800\n",
      "Epoch: 1756, loss: 0.31800\n",
      "Epoch: 1758, loss: 0.31800\n",
      "Epoch: 1760, loss: 0.31800\n",
      "Epoch: 1762, loss: 0.31800\n",
      "Epoch: 1764, loss: 0.31800\n",
      "Epoch: 1766, loss: 0.31800\n",
      "Epoch: 1768, loss: 0.31800\n",
      "Epoch: 1770, loss: 0.31800\n",
      "Epoch: 1772, loss: 0.31800\n",
      "Epoch: 1774, loss: 0.31800\n",
      "Epoch: 1776, loss: 0.31800\n",
      "Epoch: 1778, loss: 0.31800\n",
      "Epoch: 1780, loss: 0.31800\n",
      "Epoch: 1782, loss: 0.31800\n",
      "Epoch: 1784, loss: 0.31800\n",
      "Epoch: 1786, loss: 0.31800\n",
      "Epoch: 1788, loss: 0.31800\n",
      "Epoch: 1790, loss: 0.31800\n",
      "Epoch: 1792, loss: 0.31800\n",
      "Epoch: 1794, loss: 0.31800\n",
      "Epoch: 1796, loss: 0.31800\n",
      "Epoch: 1798, loss: 0.31800\n",
      "Epoch: 1800, loss: 0.31800\n",
      "Epoch: 1802, loss: 0.31800\n",
      "Epoch: 1804, loss: 0.31800\n",
      "Epoch: 1806, loss: 0.31800\n",
      "Epoch: 1808, loss: 0.31800\n",
      "Epoch: 1810, loss: 0.31800\n",
      "Epoch: 1812, loss: 0.31800\n",
      "Epoch: 1814, loss: 0.31800\n",
      "Epoch: 1816, loss: 0.31800\n",
      "Epoch: 1818, loss: 0.31800\n",
      "Epoch: 1820, loss: 0.31800\n",
      "Epoch: 1822, loss: 0.31800\n",
      "Epoch: 1824, loss: 0.31800\n",
      "Epoch: 1826, loss: 0.31800\n",
      "Epoch: 1828, loss: 0.31800\n",
      "Epoch: 1830, loss: 0.31800\n",
      "Epoch: 1832, loss: 0.31800\n",
      "Epoch: 1834, loss: 0.31800\n",
      "Epoch: 1836, loss: 0.31800\n",
      "Epoch: 1838, loss: 0.31800\n",
      "Epoch: 1840, loss: 0.31800\n",
      "Epoch: 1842, loss: 0.31800\n",
      "Epoch: 1844, loss: 0.31800\n",
      "Epoch: 1846, loss: 0.31800\n",
      "Epoch: 1848, loss: 0.31800\n",
      "Epoch: 1850, loss: 0.31800\n",
      "Epoch: 1852, loss: 0.31800\n",
      "Epoch: 1854, loss: 0.31800\n",
      "Epoch: 1856, loss: 0.31800\n",
      "Epoch: 1858, loss: 0.31800\n",
      "Epoch: 1860, loss: 0.31800\n",
      "Epoch: 1862, loss: 0.31800\n",
      "Epoch: 1864, loss: 0.31800\n",
      "Epoch: 1866, loss: 0.31800\n",
      "Epoch: 1868, loss: 0.31800\n",
      "Epoch: 1870, loss: 0.31800\n",
      "Epoch: 1872, loss: 0.31800\n",
      "Epoch: 1874, loss: 0.31800\n",
      "Epoch: 1876, loss: 0.31800\n",
      "Epoch: 1878, loss: 0.31800\n",
      "Epoch: 1880, loss: 0.31800\n",
      "Epoch: 1882, loss: 0.31800\n",
      "Epoch: 1884, loss: 0.31800\n",
      "Epoch: 1886, loss: 0.31800\n",
      "Epoch: 1888, loss: 0.31800\n",
      "Epoch: 1890, loss: 0.31800\n",
      "Epoch: 1892, loss: 0.31800\n",
      "Epoch: 1894, loss: 0.31800\n",
      "Epoch: 1896, loss: 0.31800\n",
      "Epoch: 1898, loss: 0.31800\n",
      "Epoch: 1900, loss: 0.31800\n",
      "Epoch: 1902, loss: 0.31800\n",
      "Epoch: 1904, loss: 0.31800\n",
      "Epoch: 1906, loss: 0.31800\n",
      "Epoch: 1908, loss: 0.31800\n",
      "Epoch: 1910, loss: 0.31800\n",
      "Epoch: 1912, loss: 0.31800\n",
      "Epoch: 1914, loss: 0.31800\n",
      "Epoch: 1916, loss: 0.31800\n",
      "Epoch: 1918, loss: 0.31800\n",
      "Epoch: 1920, loss: 0.31800\n",
      "Epoch: 1922, loss: 0.31800\n",
      "Epoch: 1924, loss: 0.31800\n",
      "Epoch: 1926, loss: 0.31800\n",
      "Epoch: 1928, loss: 0.31800\n",
      "Epoch: 1930, loss: 0.31800\n",
      "Epoch: 1932, loss: 0.31800\n",
      "Epoch: 1934, loss: 0.31800\n",
      "Epoch: 1936, loss: 0.31800\n",
      "Epoch: 1938, loss: 0.31800\n",
      "Epoch: 1940, loss: 0.31800\n",
      "Epoch: 1942, loss: 0.31800\n",
      "Epoch: 1944, loss: 0.31800\n",
      "Epoch: 1946, loss: 0.31800\n",
      "Epoch: 1948, loss: 0.31800\n",
      "Epoch: 1950, loss: 0.31800\n",
      "Epoch: 1952, loss: 0.31800\n",
      "Epoch: 1954, loss: 0.31800\n",
      "Epoch: 1956, loss: 0.31800\n",
      "Epoch: 1958, loss: 0.31800\n",
      "Epoch: 1960, loss: 0.31800\n",
      "Epoch: 1962, loss: 0.31800\n",
      "Epoch: 1964, loss: 0.31800\n",
      "Epoch: 1966, loss: 0.31800\n",
      "Epoch: 1968, loss: 0.31800\n",
      "Epoch: 1970, loss: 0.31800\n",
      "Epoch: 1972, loss: 0.31800\n",
      "Epoch: 1974, loss: 0.31800\n",
      "Epoch: 1976, loss: 0.31800\n",
      "Epoch: 1978, loss: 0.31800\n",
      "Epoch: 1980, loss: 0.31800\n",
      "Epoch: 1982, loss: 0.31800\n",
      "Epoch: 1984, loss: 0.31800\n",
      "Epoch: 1986, loss: 0.31800\n",
      "Epoch: 1988, loss: 0.31800\n",
      "Epoch: 1990, loss: 0.31800\n",
      "Epoch: 1992, loss: 0.31800\n",
      "Epoch: 1994, loss: 0.31800\n",
      "Epoch: 1996, loss: 0.31800\n",
      "Epoch: 1998, loss: 0.31800\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    #run model\n",
    "    outputs, (h_n, c_n) = lstm(X_tensor)\n",
    "    out = lin(h_n)\n",
    "    out = 0.5 + F.sigmoid(out)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = criterion(out, y_tensor) #calculate loss function\n",
    "\n",
    "    loss.backward() #backprop\n",
    "\n",
    "    optimizer.step() #gradient descent\n",
    "\n",
    "    #Output loss functions every 500 epochs so we can make sure the model is training\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectorbtpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
