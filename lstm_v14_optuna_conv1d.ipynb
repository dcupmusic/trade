{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pylab import mpl, plt\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2ySOLdata1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "df['signal'] = df['signal'].replace({'SignalNone': 1, 'SignalLong': 2, 'SignalShort': 0})\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vbt.Data.from_data(df)\n",
    "features = data.run(\"talib\", mavp=vbt.run_arg_dict(periods=14))\n",
    "data.data['symbol'] = pd.concat([data.data['symbol'], features], axis=1)\n",
    "data.data['symbol'].drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "# This will drop columns from the DataFrame where all values are NaN\n",
    "data.data['symbol'] = data.data['symbol'].dropna(axis=1, how='all')\n",
    "\n",
    "open_price = data.get('Open')\n",
    "high_price = data.get('High')\n",
    "low_price = data.get('Low')\n",
    "close_price = data.get('Close')\n",
    "\n",
    "data.data['symbol'] = data.data['symbol'].dropna()\n",
    "predictor_list = data.data['symbol'].drop('signal', axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "X = data.data['symbol'][predictor_list]\n",
    "\n",
    "y = data.data['symbol']['signal']\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split your data into a training+validation set and a separate test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Then, split the training+validation set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, shuffle=False)  # 0.2 here means 20% of the original data, or 25% of the training+validation set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20\n",
    "\n",
    "def create_sequences(input_data, timestep):\n",
    "    sequences = []\n",
    "    data_len = len(input_data)\n",
    "    for i in range(data_len - timestep):\n",
    "        seq = input_data[i:(i + timestep)]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "X_train_list = create_sequences(X_train_scaled, timestep)\n",
    "X_test_list = create_sequences(X_test_scaled, timestep)\n",
    "X_val_list = create_sequences(X_val_scaled, timestep)\n",
    "y_train_seq_ar = y_train[timestep:]\n",
    "y_test_seq_ar = y_test[timestep:]\n",
    "y_val_seq_ar = y_val[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ar = np.array(X_train_list)\n",
    "x_test_ar = np.array(X_test_list)  \n",
    "x_val_ar = np.array(X_val_list)  \n",
    "\n",
    "y_train_seq = np.array(y_train_seq_ar).astype(int)\n",
    "y_test_seq = np.array(y_test_seq_ar).astype(int)\n",
    "y_val_seq = np.array(y_val_seq_ar).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(x_train_ar, dtype=torch.float32) # .to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(x_test_ar, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(x_val_ar, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert y_train to a numpy array if it's a tensor\n",
    "if isinstance(y_train_seq, torch.Tensor):\n",
    "    y_train_seq_np = y_train_seq.cpu().numpy()\n",
    "else:\n",
    "    y_train_seq_np = y_train_seq  # Assuming y_train_seq is already a numpy array or similar\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_seq_np), y=y_train_seq_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "# Move class weights to the same device as your model and data\n",
    "class_weights_tensor = class_weights_tensor.to(device)  # device could be 'cpu' or 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        # Note: Adjust in_channels, out_channels, kernel_size, stride, padding as per your requirements\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # Intermediate layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer\n",
    "        \n",
    "        # Additional Dropout for the fully connected layer\n",
    "        self.dropout_fc = nn.Dropout(dropout_rate / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, input_dim]\n",
    "        # Conv1d expects input in shape [batch_size, channels, sequence_length]\n",
    "        x = x.permute(0, 2, 1)  # Reshape x to [batch_size, input_dim, sequence_length]\n",
    "        \n",
    "        # Convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape back to [batch_size, sequence_length, hidden_dim] for LSTM\n",
    "        \n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Concatenate the hidden states from both directions\n",
    "        out = torch.cat((out[:, -1, :self.hidden_dim], out[:, 0, self.hidden_dim:]), dim=1)\n",
    "        \n",
    "        # Passing through the fully connected layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout_fc(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbt.settings.set_theme('dark')\n",
    "vbt.settings['plotting']['layout']['width'] = 500\n",
    "vbt.settings['plotting']['layout']['height'] = 250\n",
    "\n",
    "num_epochs = 50\n",
    "num_trials = 10 # X_train_tensor.shape[2]\n",
    "min_total_return = -5\n",
    "# lets validate our technical indicators with the signal\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = 32 # trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = 2 # trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = 1e-3 # trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    step_size = 25 # trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = 0.85 # trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = 0.1 # trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    # Suggest a boolean flag for each feature to decide if it should be included\n",
    "    # num_features = X_train_tensor.shape[2]  # assuming the last dimension is the feature dimension\n",
    "    # included_features = [trial.suggest_categorical(f'include_feature_{i}', [True, False]) for i in range(num_features)]\n",
    "\n",
    "    # included_features_idx = [i for i, f in enumerate(included_features) if f]\n",
    "    \n",
    "    # # If no features are selected, we can either skip this trial or select a default feature\n",
    "    # if not included_features_idx:\n",
    "    #     return None  # Or handle this case as you see fit\n",
    "    \n",
    "    # Use only the selected feature to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_val_selected = X_val_tensor[:, :, feature_idx:feature_idx+1]\n",
    "    X_test_selected = X_test_tensor[:, :, feature_idx:feature_idx+1]\n",
    "  \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "    X_val_selected_gpu = X_val_selected.to(device)\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model = BiLSTMClassifier(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # # Validation step\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_output = model(X_val_selected_gpu)\n",
    "                val_loss = criterion(val_output, y_val_tensor_gpu)\n",
    "                # Convert model outputs to predicted classes\n",
    "                _, predicted_classes = torch.max(val_output, 1)\n",
    "                \n",
    "                # Convert tensors to numpy arrays for compatibility with sklearn\n",
    "                predicted_classes = predicted_classes.cpu().numpy()\n",
    "                true_classes = y_val_tensor_gpu.cpu().numpy()\n",
    "                \n",
    "                # Filter out 'hold' predictions and labels\n",
    "                buy_sell_filter = (true_classes != 1) & (predicted_classes != 1)\n",
    "                filtered_true_classes = true_classes[buy_sell_filter]\n",
    "                filtered_predicted_classes = predicted_classes[buy_sell_filter]\n",
    "                \n",
    "                if len(filtered_predicted_classes) > 0 and len(filtered_true_classes) > 0:\n",
    "                    accuracy = accuracy_score(filtered_true_classes, filtered_predicted_classes)\n",
    "                    # print(f\"Validation Accuracy (excluding 'hold'): {accuracy}\")\n",
    "                else:\n",
    "                    # print(\"Filtered classes are empty. Skipping accuracy calculation.\")\n",
    "                    accuracy = 0  # or some default value\n",
    "                \n",
    "            model.train()\n",
    "\n",
    "    # return val_loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model(X_val_selected_gpu) # (X_test_selected_gpu)\n",
    "        probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "    \n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    df_split = data.data['symbol'][-len(predicted_labels_numpy):].copy()\n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 2\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        long_exits=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "    stats = pf.stats()\n",
    "    total_return = stats['Total Return [%]']\n",
    "    orders = stats['Total Orders']\n",
    "    # max_drawdown = stats['Max Drawdown [%]']\n",
    "    sortino_ratio = stats['Sortino Ratio']\n",
    "\n",
    "    if orders < 8:\n",
    "        print(f\"Only {orders} trades were made\")\n",
    "        sortino_ratio = 0.0\n",
    "    else:\n",
    "        pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "        print(f\"Total returns: {total_return} %\")\n",
    "\n",
    "    # Return the loss as the objective to minimize it\n",
    "    # return accuracy\n",
    "    \n",
    "    # # Return the total return as the objective to maximize it\n",
    "    return sortino_ratio\n",
    "\n",
    "\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'study' is your completed Optuna study\n",
    "# Get all completed trials\n",
    "completed_trials = [trial for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "\n",
    "# Get all completed trials\n",
    "# completed_trials = study.trials\n",
    "# completed_trials\n",
    "\n",
    "# # Sort the trials based on their performance (assuming higher return is better)\n",
    "# # Note: Adjust the sorting key based on your actual return metric if necessary\n",
    "sorted_trials = sorted(completed_trials, key=lambda trial: trial.value, reverse=True)\n",
    "\n",
    "# Get the top N performing feature indices\n",
    "top_n = 5  # For example, top 5 features\n",
    "top_n_features = [trial.params['feature_idx'] for trial in sorted_trials[:top_n]]\n",
    "\n",
    "# # print(\"Top performing feature indices:\", top_n_features)\n",
    "\n",
    "# Map the indices to names\n",
    "top_performing_feature_names = [predictor_list[idx] for idx in top_n_features]\n",
    "top_performing_feature_names\n",
    "# top_n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'study' is your completed Optuna study\n",
    "\n",
    "\n",
    "# best_trial = study.best_trial\n",
    "\n",
    "# print(f\"Best trial number: {best_trial.number}\")\n",
    "# print(\"Best trial's parameters:\", best_trial.params)\n",
    "# print(\"Best trial's objective value:\", best_trial.value)\n",
    "\n",
    "\n",
    "# # Assuming best_trial.params is your dictionary\n",
    "# params = best_trial.params\n",
    "\n",
    "# # Extracting feature indices for which the value is True\n",
    "# included_feature_indices = [int(key.split('_')[-1]) for key, value in params.items() if value]\n",
    "\n",
    "# print(\"Included feature indices:\", included_feature_indices)\n",
    "\n",
    "# # Map the indices to names\n",
    "# top_performing_feature_names = [predictor_list[idx] for idx in included_feature_indices]\n",
    "\n",
    "# print(\"Top performing feature names:\", top_performing_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_trials_2 = 10\n",
    "min_total_return = 10\n",
    "num_epochs_2 = 500\n",
    "\n",
    "\n",
    "def objective_2(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    step_size = trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    # feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "    # Suggest a boolean flag for each feature to decide if it should be included\n",
    "    # num_features = X_train_tensor.shape[2]  # assuming the last dimension is the feature dimension\n",
    "    included_features = [trial.suggest_categorical(f'include_top_feature_{i}', [True, False]) for i in top_n_features]\n",
    "\n",
    "    included_features_idx = [i for i, f in enumerate(included_features) if f]\n",
    "    \n",
    "    # If no features are selected, we can either skip this trial or select a default feature\n",
    "    if not included_features_idx:\n",
    "        return None  # Or handle this case as you see fit\n",
    "    \n",
    "    my_feats = [43, 150, 87]\n",
    "    \n",
    "    # Use only the selected features to create new tensors\n",
    "    X_train_selected = X_train_tensor[:, :, my_feats] # top_n_features]\n",
    "    X_val_selected = X_val_tensor[:, :, my_feats] # top_n_features]\n",
    "    X_test_selected = X_test_tensor[:, :, my_feats] # top_n_features]\n",
    "\n",
    "    # Initialize model and move it to the MPS device\n",
    "    model_2 = BiLSTMClassifier(input_dim=len(my_feats), hidden_dim=hidden_dim, num_layers=num_layers, output_dim=len(np.unique(y_train_tensor.cpu().numpy())), dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model_2.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_val_tensor_gpu = X_val_tensor.to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.to(device)\n",
    "    X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "    y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "    \n",
    "    # Move the selected feature tensors to the GPU\n",
    "    X_train_selected_gpu = X_train_selected.to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "    X_test_selected_gpu = X_test_selected.to(device)\n",
    "    X_val_selected_gpu = X_val_selected.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    model_2.train()\n",
    "    for epoch in range(num_epochs_2):  # use a small number of epochs for demonstration\n",
    "        optimizer.zero_grad()\n",
    "        output = model_2(X_train_selected_gpu)\n",
    "        loss = criterion(output, y_train_tensor_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # # Validation step\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch} loss: {loss.item()}\")\n",
    "        \n",
    "        \n",
    "    model_2.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model_2(X_val_selected_gpu) # (X_test_selected_gpu)\n",
    "        probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "\n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    df_split = data.data['symbol'][-len(predicted_labels_numpy):].copy()\n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 2\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        long_exits=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "\n",
    "    stats = pf.stats()\n",
    "    total_return = stats['Total Return [%]']\n",
    "    orders = stats['Total Orders']\n",
    "    calmer_ratio = stats['Calmar Ratio']\n",
    "\n",
    "    if orders < 10:\n",
    "        print(f\"Only {orders} trades were made\")\n",
    "        calmer_ratio = 0.0\n",
    "    else:\n",
    "        pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "    \n",
    "    # Return the negative total return as the objective to maximize it\n",
    "    return calmer_ratio\n",
    "\n",
    "# Before running the study, ensure your data tensors are on the CPU as Optuna will handle moving them to the GPU\n",
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n",
    "\n",
    "study_2 = optuna.create_study(direction='maximize')\n",
    "study_2.optimize(objective_2, n_trials=num_trials_2)\n",
    "\n",
    "print(f'Best trial:', study_2.best_trial.number, study_2.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'study_2' is your completed Optuna study\n",
    "\n",
    "\n",
    "best_trial_2 = study_2.best_trial\n",
    "\n",
    "print(f\"Best trial number: {best_trial_2.number}\")\n",
    "print(\"Best trial's parameters:\", best_trial_2.params)\n",
    "print(\"Best trial's objective value:\", best_trial_2.value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming best_trial.params is your dictionary\n",
    "params_2 = best_trial_2.params\n",
    "params_2\n",
    "\n",
    "\n",
    "# Extracting feature indices for which the value is True\n",
    "# included_feature_indices = [int(key.split('_')[-1]) for key, value in params_2.items() if value]\n",
    "\n",
    "# print(\"Included feature indices:\", included_feature_indices)\n",
    "\n",
    "# # Map the indices to names\n",
    "# top_performing_feature_names = [predictor_list[idx] for idx in included_feature_indices]\n",
    "\n",
    "# print(\"Top performing feature names:\", top_performing_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
