{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pylab import mpl, plt\n",
    "import random\n",
    "import optuna\n",
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for MPS (GPU on M1 Mac) availability and set it as the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1ySOLdata1hTA.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window size\n",
    "window_size = 50\n",
    "data_trimmed = df.copy()\n",
    "data_trimmed.loc[:, 'signal'] = 'SignalNone'\n",
    "\n",
    "rolling_max = data_trimmed.loc[:,'Close'].rolling(window=2*window_size+1, center=True, min_periods=1).max()\n",
    "rolling_min = data_trimmed.loc[:,'Close'].rolling(window=2*window_size+1, center=True, min_periods=1).min()\n",
    "\n",
    "is_peak = (data_trimmed.loc[:, 'Close'] == rolling_max)\n",
    "\n",
    "is_low = (data_trimmed.loc[:, 'Close'] == rolling_min) \n",
    "\n",
    "# Update signal columns where conditions are met\n",
    "data_trimmed.loc[is_peak, 'signal'] = 'SignalShort'  # Mark peaks with SignalShort\n",
    "data_trimmed.loc[is_low, 'signal'] = 'SignalLong'   # Mark lows with SignalLong\n",
    "df = data_trimmed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtered = df[df['signal'] != 'SignalNone']\n",
    "\n",
    "# Iterate through the DataFrame and adjust the signals\n",
    "for i in range(1, len(df_filtered)):\n",
    "    current_signal = df_filtered.iloc[i]['signal']\n",
    "    previous_signal = df_filtered.iloc[i - 1]['signal']\n",
    "    current_close = df_filtered.iloc[i]['Close']\n",
    "    previous_close = df_filtered.iloc[i - 1]['Close']\n",
    "    \n",
    "    if current_signal == previous_signal:\n",
    "        if current_signal == 'SignalLong' and previous_close > current_close:\n",
    "            df_filtered.iloc[i - 1, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "        elif current_signal != 'SignalLong' and previous_close < current_close:\n",
    "            df_filtered.iloc[i - 1, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "        else:\n",
    "            df_filtered.iloc[i, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "\n",
    "\n",
    "df.update(df_filtered)\n",
    "\n",
    "if binary:\n",
    "    # Assuming df is your DataFrame\n",
    "    previous_signal = None  # Initialize a variable to keep track of the previous non-\"SignalNone\" value\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i, df_filtered.columns.get_loc('signal')] == \"SignalNone\" and previous_signal is not None:\n",
    "            df.iloc[i, df_filtered.columns.get_loc('signal')] = previous_signal  # Replace \"SignalNone\" with the previous signal\n",
    "        elif df.iloc[i, df_filtered.columns.get_loc('signal')] != \"SignalNone\":\n",
    "            previous_signal = df.iloc[i, df_filtered.columns.get_loc('signal')]  # Update the previous signal to the current one if it's not \"SignalNone\"\n",
    "\n",
    "    df = df.loc[df['signal'] != 'SignalNone']\n",
    "\n",
    "df['signal'] = df['signal'].replace({'SignalLong': 1, 'SignalShort': 0, 'SignalNone': 2})\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vbt.IF.list_indicators(\"talib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vbt.phelp(vbt.talib(\"STOCHRSI\").run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vbt.Data.from_data(df)\n",
    "\n",
    "\n",
    "data.data['symbol'].drop(['price', 'Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "# This will drop columns from the DataFrame where all values are NaN\n",
    "data.data['symbol'] = data.data['symbol'].dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "data.data['symbol'] = data.data['symbol'].dropna()\n",
    "predictor_list = data.data['symbol'].drop('signal', axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "X = data.data['symbol'][predictor_list]\n",
    "\n",
    "y = data.data['symbol']['signal']\n",
    "\n",
    "X.columns = X.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "# Assuming X is a DataFrame or a NumPy array\n",
    "indices = np.arange(X.shape[0])\n",
    "\n",
    "# First, split your data into a training+validation set and a separate test set\n",
    "X_train_val, X_test, y_train_val, y_test, indices_train_val, indices_test = train_test_split(X, y, indices, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Then, split the training+validation set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(X_train_val, y_train_val, indices_train_val, test_size=0.3, shuffle=False)  # 0.2 here means 20% of the original data, or 25% of the training+validation set\n",
    "\n",
    "# Now, `indices_val` holds the indices of your original dataset that were used for the validation set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20\n",
    "\n",
    "def create_sequences(input_data, timestep):\n",
    "    sequences = []\n",
    "    data_len = len(input_data)\n",
    "    for i in range(data_len - timestep):\n",
    "        seq = input_data[i:(i + timestep)]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "X_train_list = create_sequences(X_train_scaled, timestep)\n",
    "X_val_list = create_sequences(X_val_scaled, timestep)\n",
    "X_test_list = create_sequences(X_test_scaled, timestep)\n",
    "y_train_seq_ar = y_train[timestep:]\n",
    "y_val_seq_ar = y_val[timestep:]\n",
    "y_test_seq_ar = y_test[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x_train_ar = np.array(X_train_list)\n",
    "y_train_seq = np.array(y_train_seq_ar).astype(int)\n",
    "x_val_ar = np.array(X_val_list)  \n",
    "y_val_seq = np.array(y_val_seq_ar).astype(int)\n",
    "x_test_ar = np.array(X_test_list)  \n",
    "y_test_seq = np.array(y_test_seq_ar).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(x_train_ar, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(x_val_ar, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(x_test_ar, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.long)\n",
    "\n",
    "if binary:\n",
    "    y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val_seq, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_seq, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary:\n",
    "    class_weights_tensor = torch.tensor([1.0, 1.0, 1.0])\n",
    "else:\n",
    "    if isinstance(y_train_seq, torch.Tensor):\n",
    "        y_train_seq_np = y_train_seq.cpu().numpy()\n",
    "    else:\n",
    "        y_train_seq_np = y_train_seq  # Assuming y_train_seq is already a numpy array or similar\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_seq_np), y=y_train_seq_np)\n",
    "\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "    # Move class weights to the same device as your model and data\n",
    "    class_weights_tensor = class_weights_tensor.to(device)  # device could be 'cpu' or 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        # lstm_output shape: [batch_size, seq_length, hidden_dim]\n",
    "        weights = torch.tanh(self.linear(lstm_output))\n",
    "        weights = F.softmax(weights, dim=1)\n",
    "        \n",
    "        # Context vector with weighted sum\n",
    "        context = weights * lstm_output\n",
    "        context = torch.sum(context, dim=1)\n",
    "        return context, weights\n",
    "\n",
    "class BiLSTMClassifierWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):\n",
    "        super(BiLSTMClassifierWithAttention, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Batch Normalization Layer for Conv1d\n",
    "        self.bn_conv1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Attention Layer\n",
    "        self.attention = Attention(hidden_dim * 2)  # For bidirectional LSTM\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # Adjusted for attention context vector\n",
    "        \n",
    "        # Batch Normalization Layer for FC1\n",
    "        self.bn_fc1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer\n",
    "        \n",
    "        # Additional Dropout for the fully connected layer\n",
    "        self.dropout_fc = nn.Dropout(dropout_rate / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape x for Conv1d\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn_conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Reshape back for LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Applying attention mechanism to LSTM outputs\n",
    "        context, _ = self.attention(out)\n",
    "        \n",
    "        # Fully connected layers using the context vector from attention\n",
    "        out = self.fc1(context)\n",
    "        out = self.bn_fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout_fc(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### financial functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, X_val_selected_gpu):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model(X_val_selected_gpu)\n",
    "        if binary:\n",
    "            probabilities = torch.sigmoid(y_test_pred).squeeze()\n",
    "            predicted_labels = (probabilities > 0.5).long()\n",
    "        else:    \n",
    "            probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "\n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    adjusted_indices_val = indices_val[timestep:]\n",
    "    adjusted_indices_test = indices_test[timestep:] \n",
    "\n",
    "    df_split = data.data['symbol'].iloc[adjusted_indices_val].copy()\n",
    "    \n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 1\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        short_entries=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "    stats = pf.stats()\n",
    "    total_return = round(stats['Total Return [%]'], 2)\n",
    "    vbt.settings.set_theme('dark')\n",
    "    vbt.settings['plotting']['layout']['width'] = 600\n",
    "    vbt.settings['plotting']['layout']['height'] = 200\n",
    "    pf.plot({\"orders\", \"cum_returns\"}).show()\n",
    "    print(f\"Total Return: {total_return}%\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_financials(model, X_val_selected_gpu):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model(X_val_selected_gpu)\n",
    "        if binary:\n",
    "            probabilities = torch.sigmoid(y_test_pred).squeeze()\n",
    "            predicted_labels = (probabilities > 0.5).long()\n",
    "        else:    \n",
    "            probabilities = torch.softmax(y_test_pred, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, 1)\n",
    "        predicted_labels_numpy = predicted_labels.cpu().numpy()\n",
    "\n",
    "    # Use predicted labels to simulate a trading strategy\n",
    "    adjusted_indices_val = indices_val[timestep:]\n",
    "    adjusted_indices_test = indices_test[timestep:] \n",
    "    \n",
    "    df_split = data.data['symbol'].iloc[adjusted_indices_val].copy()\n",
    "    df_split.loc[:, \"signal\"] = predicted_labels_numpy\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 1\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        short_entries=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "    stats = pf.stats()\n",
    "    total_return = stats['Total Return [%]']\n",
    "    orders = stats['Total Orders']\n",
    "    calmer_ratio = stats['Calmar Ratio']\n",
    "    \n",
    "    model.train()\n",
    "    return {\n",
    "        \"orders\": orders,\n",
    "        \"calmer_returns\": (calmer_ratio+total_return)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target():\n",
    "    adjusted_indices_val = indices_val[timestep:]\n",
    "    adjusted_indices_test = indices_test[timestep:] \n",
    "\n",
    "    df_split = data.data['symbol'].iloc[adjusted_indices_val].copy()\n",
    "    df_split.loc[:, \"signal\"] = y_val_tensor\n",
    "    signal = df_split['signal']\n",
    "    entries = signal == 1\n",
    "    exits = signal == 0\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=df_split.Close, \n",
    "        long_entries=entries, \n",
    "        short_entries=exits,\n",
    "        size=100,\n",
    "        size_type='value',\n",
    "        init_cash='auto'\n",
    "    )\n",
    "    stats = pf.stats()\n",
    "    vbt.settings.set_theme('dark')\n",
    "    vbt.settings['plotting']['layout']['width'] = 600\n",
    "    vbt.settings['plotting']['layout']['height'] = 200\n",
    "    pf.plot({\"orders\", \"cum_returns\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_binary_with_metrics(model, criterion, X_val, y_val, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(X_val)\n",
    "        predicted_probs = torch.sigmoid(output)\n",
    "        predictions = (predicted_probs > 0.5).float()  # Apply threshold to get binary predictions\n",
    "        loss = criterion(output, y_val.view_as(output))\n",
    "\n",
    "        # Convert to CPU and numpy for sklearn metrics\n",
    "        predictions_np = predictions.cpu().numpy()\n",
    "        y_val_np = y_val.cpu().numpy()\n",
    "        predicted_probs_np = predicted_probs.cpu().numpy()\n",
    "\n",
    "        accuracy = (predictions.view_as(y_val) == y_val).sum().item() / len(y_val)\n",
    "        precision = precision_score(y_val_np, predictions_np)\n",
    "        recall = recall_score(y_val_np, predictions_np)\n",
    "        f1 = f1_score(y_val_np, predictions_np)\n",
    "        auc = roc_auc_score(y_val_np, predicted_probs_np)  # Use probabilities for AUC\n",
    "\n",
    "    model.train()  # Set back to train mode\n",
    "    return {\n",
    "        'loss': round(loss.item(),4),\n",
    "        'accuracy': round(accuracy,4),\n",
    "        'precision': round(precision,4),\n",
    "        'recall': round(recall,4),\n",
    "        'f1': round(f1,4),\n",
    "        'auc': round(auc,4)\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_multi_with_metrics(model, criterion, X_val, y_val, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(X_val)\n",
    "        predicted_probs = torch.softmax(output, dim=1)\n",
    "        predictions = torch.argmax(predicted_probs, dim=1)  # Get the index of the max log-probability as the prediction\n",
    "        \n",
    "        loss = criterion(output, y_val)  # Ensure y_val is of dtype long and contains class indices\n",
    "\n",
    "        # Convert to CPU and numpy for sklearn metrics\n",
    "        predictions_np = predictions.cpu().numpy()\n",
    "        y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "        accuracy = accuracy_score(y_val_np, predictions_np)\n",
    "        precision = precision_score(y_val_np, predictions_np, average='weighted')\n",
    "        recall = recall_score(y_val_np, predictions_np, average='weighted')\n",
    "        f1 = f1_score(y_val_np, predictions_np, average='weighted')\n",
    "\n",
    "    model.train()  # Set back to train mode\n",
    "    return {\n",
    "        'loss': round(loss.item(), 4),\n",
    "        'accuracy': round(accuracy, 4),\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1': round(f1, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vals(epoch_nums_1, val_loss, accuracy, precision, recall, f1):\n",
    "    # Create a subplot with 2 rows and 1 column\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "    # Add validation loss trace to the first row\n",
    "    fig.add_trace(go.Scatter(x=epoch_nums_1, y=val_loss, mode='lines+markers', name='val_loss'), row=1, col=1)\n",
    "    \n",
    "    # Add validation metrics traces to the second row\n",
    "    fig.add_trace(go.Scatter(x=epoch_nums_1, y=accuracy, mode='lines+markers', name='accuracy'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=epoch_nums_1, y=precision, mode='lines+markers', name='precision'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=epoch_nums_1, y=recall, mode='lines+markers', name='recall'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=epoch_nums_1, y=f1, mode='lines+markers', name='f1'), row=2, col=1)\n",
    "\n",
    "    # Update layout for the combined figure\n",
    "    fig.update_layout(\n",
    "        template='plotly_dark',\n",
    "        autosize=False,\n",
    "        width=700,  \n",
    "        height=300, \n",
    "        title_text='loss & metrics over epochs',\n",
    "        title_font_size=10,\n",
    "        margin=dict(l=5, r=5, b=5, t=30, pad=5),\n",
    "        legend=dict(\n",
    "            font=dict(\n",
    "                size=5)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show the combined figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_returns(epoch_nums_1, calmer_return):\n",
    "    return_metrics_fig = go.Figure()\n",
    "\n",
    "    return_metrics_fig.add_trace(go.Scatter(x=epoch_nums_1, y=calmer_return, mode='lines+markers', name='calmer returns'))\n",
    "\n",
    "    return_metrics_fig.update_layout(\n",
    "        template='plotly_dark',\n",
    "        autosize=False,\n",
    "        width=700,  # Set the width of the figure\n",
    "        height=150,  # Set the height of the figure\n",
    "        title='calmer ratio + returns over epochs',  # You can set the title directly here\n",
    "        title_font_size=10,\n",
    "        margin=dict(l=5, r=5, b=5, t=30, pad=5),\n",
    "        legend=dict(\n",
    "            font=dict(\n",
    "                size=5)\n",
    "        )\n",
    "    )\n",
    "    return_metrics_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Step 3: Save the trained model\n",
    "def save_model(model, model_filename='trained_model.joblib'):\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f'Model saved as {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "learning_rate=0.5\n",
    "step_size=10\n",
    "gamma=0.8\n",
    "dropout_rate=0.05\n",
    "neurons = 160\n",
    "\n",
    "variance_threshold = 0.5\n",
    "print_epochs = 30\n",
    "rolling_window_size = 20\n",
    "num_epochs = 300\n",
    "num_trials = 1\n",
    "indicator_offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### study training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 11:53:31,658] A new study created in memory with name: no-name-3030299e-462e-4608-af8b-26f84886e8ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 Indicators indicies: [3, 4, 8, 11, 12, 16, 17, 19, 20, 21, 26, 27, 28, 32, 33, 37, 40, 41, 42, 43, 45, 46, 48, 49, 50, 54, 56, 57, 58, 60, 61, 63, 67, 69, 72, 73, 74, 75, 77]\n",
      "Trial 0 Indicators names: ['abands_middle', 'abands_lower', 'adxr', 'aroonosc', 'atr', 'bbands_middle', 'bbands_lower', 'cci', 'chop', 'cmo', 'donchian_middle', 'donchian_lower', 'dpo', 'ht_dcperiod', 'ht_dcphase', 'ichi', 'keltner_upper', 'keltner_middle', 'keltner_lower', 'kri', 'linearreg', 'macdfix_macd', 'macdfix_hist', 'mama', 'mfi', 'natr', 'plusdi', 'ppo', 'rocp', 'sar', 'sma', 'stochf_fastD', 'tema', 'trima', 'tsi', 'udrsi', 'ultosc', 'var', 'wws']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 11:55:32,492] Trial 0 finished with value: -100.35 and parameters: {'include_feature_2': False, 'include_feature_3': True, 'include_feature_4': True, 'include_feature_5': False, 'include_feature_6': False, 'include_feature_7': False, 'include_feature_8': True, 'include_feature_9': False, 'include_feature_10': False, 'include_feature_11': True, 'include_feature_12': True, 'include_feature_13': False, 'include_feature_14': False, 'include_feature_15': False, 'include_feature_16': True, 'include_feature_17': True, 'include_feature_18': False, 'include_feature_19': True, 'include_feature_20': True, 'include_feature_21': True, 'include_feature_22': False, 'include_feature_23': False, 'include_feature_24': False, 'include_feature_25': False, 'include_feature_26': True, 'include_feature_27': True, 'include_feature_28': True, 'include_feature_29': False, 'include_feature_30': False, 'include_feature_31': False, 'include_feature_32': True, 'include_feature_33': True, 'include_feature_34': False, 'include_feature_35': False, 'include_feature_36': False, 'include_feature_37': True, 'include_feature_38': False, 'include_feature_39': False, 'include_feature_40': True, 'include_feature_41': True, 'include_feature_42': True, 'include_feature_43': True, 'include_feature_44': False, 'include_feature_45': True, 'include_feature_46': True, 'include_feature_47': False, 'include_feature_48': True, 'include_feature_49': True, 'include_feature_50': True, 'include_feature_51': False, 'include_feature_52': False, 'include_feature_53': False, 'include_feature_54': True, 'include_feature_55': False, 'include_feature_56': True, 'include_feature_57': True, 'include_feature_58': True, 'include_feature_59': False, 'include_feature_60': True, 'include_feature_61': True, 'include_feature_62': False, 'include_feature_63': True, 'include_feature_64': False, 'include_feature_65': False, 'include_feature_66': False, 'include_feature_67': True, 'include_feature_68': False, 'include_feature_69': True, 'include_feature_70': False, 'include_feature_71': False, 'include_feature_72': True, 'include_feature_73': True, 'include_feature_74': True, 'include_feature_75': True, 'include_feature_76': False, 'include_feature_77': True}. Best is trial 0 with value: -100.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as trained_model.joblib\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    # hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64])\n",
    "    # num_layers = trial.suggest_int('num_layers', 2, 3)\n",
    "    # learning_rate = trial.suggest_float('lr', 1e-3, 1e-1, log=True)\n",
    "    # step_size = trial.suggest_int('step_size', 10, 100)\n",
    "    # gamma = trial.suggest_float('gamma', 0.85, 0.99)\n",
    "    # dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    # feature_idx = trial.suggest_int('feature_idx', 0, X_train_tensor.shape[2] - 1)\n",
    "\n",
    "\n",
    "    ''' multi feature selection'''\n",
    "    # Suggest a boolean flag for each feature to decide if it should be included\n",
    "    num_features = X_train_tensor.shape[2] - 3\n",
    "    included_features = [trial.suggest_categorical(f'include_feature_{i+indicator_offset}', [True, False]) for i in range(2, num_features+2)]\n",
    "    additional_features_idx = [i for i, f in enumerate(included_features, start=2+indicator_offset) if f]\n",
    "\n",
    "    # Prepend indices 0 and 1 to ensure they are always included\n",
    "    included_features_idx = [0, 1] + additional_features_idx\n",
    "\n",
    "    if len(included_features_idx) <= 2:\n",
    "        print(f\"No features were selected for trial {trial.number}. Skipping...\")\n",
    "        return 0\n",
    "    \n",
    "    selected_predictors = [predictor_list[i] for i in additional_features_idx]\n",
    "    print(f\"Trial {trial.number} Indicators indicies: {additional_features_idx}\")\n",
    "    print(f\"Trial {trial.number} Indicators names: {selected_predictors}\")\n",
    "    \n",
    "    # Use a selection of features to create new tensors\n",
    "    # X_train_selected = X_train_tensor[:, :, included_features_idx]\n",
    "    # X_val_selected = X_val_tensor[:, :, included_features_idx]\n",
    "    \n",
    "    X_train_selected = X_train_tensor\n",
    "    X_val_selected = X_val_tensor\n",
    "    \n",
    "    # Move tensors to the MPS device\n",
    "    X_train_selected_gpu = X_train_selected.float().to(device)\n",
    "    X_val_selected_gpu = X_val_selected.float().to(device)\n",
    "    y_train_tensor_gpu = y_train_tensor.long().to(device)\n",
    "    y_val_tensor_gpu = y_val_tensor.long().to(device)\n",
    "    \n",
    "    out_dims = len(np.unique(y_train_tensor.cpu().numpy()))\n",
    "    if binary:\n",
    "        out_dims = 1\n",
    "        y_train_tensor_gpu = y_train_tensor.float().to(device)\n",
    "        y_val_tensor_gpu = y_val_tensor.float().to(device)\n",
    "    \n",
    "    # Create the model with bidirectional LSTM\n",
    "    model = BiLSTMClassifierWithAttention(input_dim=X_train_selected.shape[-1], hidden_dim=hidden_dim, num_layers=num_layers, output_dim=out_dims, dropout_rate=dropout_rate).to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=step_size, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    if binary:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        y_val_tensor_gpu = y_val_tensor_gpu.unsqueeze(1)\n",
    "        \n",
    "\n",
    "\n",
    "    rolling_window = deque(maxlen=rolling_window_size)\n",
    "    epoch_nums_1 = []\n",
    "    calmer_return = []\n",
    "    val_loss = []\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []        \n",
    "   \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimiser.zero_grad()   \n",
    "        output = model(X_train_selected_gpu)\n",
    "        output = torch.squeeze(output)  # This removes the extra dimension\n",
    "        loss = criterion(output, y_train_tensor_gpu)  # Ensure y_train is of type torch.long\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        financial_results = validate_financials(model, X_val_selected_gpu)\n",
    "        \n",
    "        validation_results = validate_multi_with_metrics(model, criterion, X_val_selected_gpu, y_val_tensor_gpu, device)\n",
    "        if binary:\n",
    "            validation_results = validate_binary_with_metrics(model, criterion, X_val_selected_gpu, y_val_tensor_gpu, device)\n",
    "\n",
    "        if epoch % print_epochs == 0:  # Adjust as needed\n",
    "\n",
    "            epoch_nums_1.append(epoch)\n",
    "            accuracy.append(validation_results['accuracy'])\n",
    "            val_loss.append(loss.item())\n",
    "            precision.append(validation_results['precision'])\n",
    "            recall.append(validation_results['recall'])\n",
    "            f1.append(validation_results['f1'])\n",
    "            calmer_return.append(financial_results['calmer_returns'])\n",
    "            rolling_window.append(financial_results['calmer_returns'])\n",
    "            \n",
    "            if len(rolling_window) == rolling_window_size:\n",
    "                variance = np.var(list(rolling_window))\n",
    "                \n",
    "                if variance < variance_threshold:\n",
    "                    print(f\"Early stopping triggered epoch {epoch}. Variance is below the threshold.\")\n",
    "                    break\n",
    "                if len(calmer_return) >= rolling_window_size and all(x < 0 for x in calmer_return[-rolling_window_size:]):\n",
    "                    print(f\"Early stopping triggered epoch {epoch}. The last {rolling_window_size} returns are negative.\")\n",
    "                    break\n",
    "            \n",
    "    if (financial_results['orders'] > 4):\n",
    "        save_model(model)\n",
    "        if (financial_results['calmer_returns'] > 0):\n",
    "            plot_vals(epoch_nums_1, val_loss, accuracy, precision, recall, f1)\n",
    "            plot_returns(epoch_nums_1, calmer_return)\n",
    "            backtest(model, X_val_selected_gpu)\n",
    "            print(f\"Loss: {loss.item()}\")\n",
    "            del X_train_selected_gpu, X_val_selected_gpu, y_train_tensor_gpu, y_val_tensor_gpu\n",
    "            torch.cuda.empty_cache()  # Clears memory cache that's no longer used\n",
    "        return round(financial_results['calmer_returns'], 2)\n",
    "    else:\n",
    "        print(f\"Results were no good. Orders: {financial_results['orders']}, calmer_return: {financial_results['calmer_returns']}\")\n",
    "        save_model(model)\n",
    "        del X_train_selected_gpu, X_val_selected_gpu, y_train_tensor_gpu, y_val_tensor_gpu\n",
    "        torch.cuda.empty_cache()  # Clears memory cache that's no longer used\n",
    "        return 0\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "# print('Best trial:', study.best_trial.params)\n",
    "\n",
    "torch.cuda.empty_cache()  # Final cleanup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a dictionary to hold the aggregate score for each feature index\n",
    "feature_scores = defaultdict(float)\n",
    "\n",
    "# Initialize a dictionary to count the occurrences of each feature index\n",
    "feature_counts = defaultdict(int)\n",
    "\n",
    "# Iterate through all completed trials in the study\n",
    "for trial in study.trials:\n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        # Extract feature indices for which the parameter value is True\n",
    "        feature_indices = [int(key.split('_')[-1]) for key, value in trial.params.items() if value]\n",
    "        \n",
    "        # Assign scores to each feature index based on the trial's objective value\n",
    "        for idx in feature_indices:\n",
    "            feature_scores[idx] += trial.value  # Or use any other metric or transformation of the trial's objective value\n",
    "            feature_counts[idx] += 1\n",
    "\n",
    "# Calculate the average score for each feature index (optional)\n",
    "for idx in feature_scores:\n",
    "    feature_scores[idx] /= feature_counts[idx]\n",
    "\n",
    "# Sort feature indices based on their scores, highest first\n",
    "sorted_feature_indices = sorted(feature_scores, key=feature_scores.get, reverse=True)\n",
    "sorted_feature_names = [predictor_list[i] for i in sorted_feature_indices]\n",
    "\n",
    "\n",
    "\n",
    "# Print the ranked feature indices and their scores\n",
    "for idx in sorted_feature_indices:\n",
    "    print(f\"Feature index: {idx}, Score: {feature_scores[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scores in the same order as the sorted indices\n",
    "scores = [feature_scores[idx] for idx in sorted_feature_indices]\n",
    "\n",
    "# Create a bar chart\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(y=[f\"{idx}: {name}\" for idx, name in zip(sorted_feature_indices, sorted_feature_names)], x=scores, orientation='h')\n",
    "])\n",
    "\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "\n",
    "# Update chart layout for readability\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    autosize=False,\n",
    "    width=700,  \n",
    "    height=800,\n",
    "    title=\"Feature Index Scores\",\n",
    "    xaxis_title=\"Feature Index\",\n",
    "    yaxis_title=\"Score\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = X_train_tensor.cpu()\n",
    "y_train_tensor = y_train_tensor.cpu()\n",
    "X_val_tensor = X_val_tensor.cpu()\n",
    "y_val_tensor = y_val_tensor.cpu()\n",
    "X_test_tensor = X_test_tensor.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
