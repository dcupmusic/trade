{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc7bf9a0-e26b-4de5-8db7-7a410a9c31d1",
    "_uuid": "91e741e3-0b5a-4d10-a22e-fab5924337e5"
   },
   "source": [
    "In this notebook we will be building and training LSTM to predict IBM stock. We will use PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd \n",
    "from pylab import mpl, plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import math, time\n",
    "import itertools\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "vbt.settings.set_theme('dark')\n",
    "vbt.settings['plotting']['layout']['width'] = 800\n",
    "vbt.settings['plotting']['layout']['height'] = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.read_csv('2ySOLdata1h.csv')\n",
    "sol_data['timestamp'] = pd.to_datetime(sol_data['timestamp'], unit='s')\n",
    "sol_data.set_index('timestamp', inplace=True)\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>172.790</td>\n",
       "      <td>173.130</td>\n",
       "      <td>172.480</td>\n",
       "      <td>172.930</td>\n",
       "      <td>49675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00</th>\n",
       "      <td>172.940</td>\n",
       "      <td>173.110</td>\n",
       "      <td>171.470</td>\n",
       "      <td>171.470</td>\n",
       "      <td>68973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 06:00:00</th>\n",
       "      <td>171.490</td>\n",
       "      <td>174.310</td>\n",
       "      <td>171.340</td>\n",
       "      <td>173.220</td>\n",
       "      <td>95595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 07:00:00</th>\n",
       "      <td>173.220</td>\n",
       "      <td>173.740</td>\n",
       "      <td>172.260</td>\n",
       "      <td>172.470</td>\n",
       "      <td>95494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:00:00</th>\n",
       "      <td>172.450</td>\n",
       "      <td>173.440</td>\n",
       "      <td>172.140</td>\n",
       "      <td>173.160</td>\n",
       "      <td>57926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 02:00:00</th>\n",
       "      <td>102.718</td>\n",
       "      <td>103.063</td>\n",
       "      <td>101.208</td>\n",
       "      <td>101.411</td>\n",
       "      <td>731765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 03:00:00</th>\n",
       "      <td>101.413</td>\n",
       "      <td>101.850</td>\n",
       "      <td>100.044</td>\n",
       "      <td>100.738</td>\n",
       "      <td>970135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 04:00:00</th>\n",
       "      <td>100.734</td>\n",
       "      <td>100.939</td>\n",
       "      <td>99.635</td>\n",
       "      <td>100.743</td>\n",
       "      <td>858035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 05:00:00</th>\n",
       "      <td>100.734</td>\n",
       "      <td>102.533</td>\n",
       "      <td>100.532</td>\n",
       "      <td>101.974</td>\n",
       "      <td>879783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 06:00:00</th>\n",
       "      <td>101.982</td>\n",
       "      <td>102.576</td>\n",
       "      <td>101.270</td>\n",
       "      <td>101.366</td>\n",
       "      <td>619216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17499 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "timestamp                                                      \n",
       "2022-01-01 04:00:00  172.790  173.130  172.480  172.930   49675\n",
       "2022-01-01 05:00:00  172.940  173.110  171.470  171.470   68973\n",
       "2022-01-01 06:00:00  171.490  174.310  171.340  173.220   95595\n",
       "2022-01-01 07:00:00  173.220  173.740  172.260  172.470   95494\n",
       "2022-01-01 08:00:00  172.450  173.440  172.140  173.160   57926\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2023-12-31 02:00:00  102.718  103.063  101.208  101.411  731765\n",
       "2023-12-31 03:00:00  101.413  101.850  100.044  100.738  970135\n",
       "2023-12-31 04:00:00  100.734  100.939   99.635  100.743  858035\n",
       "2023-12-31 05:00:00  100.734  102.533  100.532  101.974  879783\n",
       "2023-12-31 06:00:00  101.982  102.576  101.270  101.366  619216\n",
       "\n",
       "[17499 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sol_data.iloc[:, 0:5].copy()\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_trimmed = data.copy()\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "data_trimmed.loc[:, 'signal'] = 'SignalNone'\n",
    "\n",
    "\n",
    "# Define window size\n",
    "window_size = 10\n",
    "\n",
    "rolling_max = data_trimmed.loc[:,'Close'].rolling(window=2*window_size+1, center=True, min_periods=1).max()\n",
    "rolling_min = data_trimmed.loc[:,'Close'].rolling(window=2*window_size+1, center=True, min_periods=1).min()\n",
    "\n",
    "is_peak = (data_trimmed.loc[:, 'Close'] == rolling_max)\n",
    "\n",
    "is_low = (data_trimmed.loc[:, 'Close'] == rolling_min) \n",
    "\n",
    "# Update signal columns where conditions are met\n",
    "data_trimmed.loc[is_peak, 'signal'] = 'SignalShort'  # Mark peaks with SignalShort\n",
    "data_trimmed.loc[is_low, 'signal'] = 'SignalLong'   # Mark lows with SignalLong\n",
    "df = data_trimmed.copy()\n",
    "df_filtered = df[df['signal'] != 'SignalNone'].copy()\n",
    "\n",
    "# Iterate through the DataFrame and adjust the signals\n",
    "for i in range(1, len(df_filtered)):\n",
    "    current_signal = df_filtered.iloc[i]['signal']\n",
    "    previous_signal = df_filtered.iloc[i - 1]['signal']\n",
    "    current_close = df_filtered.iloc[i]['Close']\n",
    "    previous_close = df_filtered.iloc[i - 1]['Close']\n",
    "    \n",
    "    if current_signal == previous_signal:\n",
    "        if current_signal == 'SignalLong' and previous_close > current_close:\n",
    "            df_filtered.iloc[i - 1, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "        elif current_signal != 'SignalLong' and previous_close < current_close:\n",
    "            df_filtered.iloc[i - 1, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "        else:\n",
    "            df_filtered.iloc[i, df_filtered.columns.get_loc('signal')] = 'SignalNone'\n",
    "\n",
    "\n",
    "df.update(df_filtered)\n",
    "\n",
    "df.loc[:,'signal'] = df.loc[:,'signal'].replace({'SignalLong': 2, 'SignalShort': 0, 'SignalNone': 1})\n",
    "df = df.ffill()\n",
    "\n",
    "df['signal'] = df['signal'].astype(float)\n",
    "long_signals = df['signal'] == 2\n",
    "short_signals = df['signal'] == 0\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 2))\n",
    "for idx in df.index[:-1]:\n",
    "    if short_signals.loc[idx]:\n",
    "        short_index = idx\n",
    "        next_long_idx = df.loc[idx:].index[long_signals[idx:]].min()\n",
    "        bear_slice = df.loc[short_index : next_long_idx].copy()\n",
    "        bear_slice['signal'] = bear_slice['Close']\n",
    "        signal_values = bear_slice['signal'].values.reshape(-1, 1)\n",
    "        scaled_signal_values = scaler.fit_transform(signal_values)\n",
    "        scaled_signal_values_transformed = 2 - (scaled_signal_values)\n",
    "        bear_slice['signal'] = scaled_signal_values_transformed.flatten()\n",
    "        df.update(bear_slice)\n",
    "    elif long_signals.loc[idx]:\n",
    "        long_index = idx\n",
    "        next_short_idx = df.loc[idx:].index[short_signals[idx:]].min()\n",
    "        bull_slice = df.loc[long_index : next_short_idx].copy()\n",
    "        bull_slice['signal'] = bull_slice['Close']\n",
    "        signal_values = bull_slice['signal'].values.reshape(-1, 1)\n",
    "        scaled_signal_values = scaler.fit_transform(signal_values)\n",
    "        scaled_signal_values_transformed = 2 - (scaled_signal_values)\n",
    "        bull_slice['signal'] = scaled_signal_values_transformed.flatten()\n",
    "        df.update(bull_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>172.79</td>\n",
       "      <td>173.13</td>\n",
       "      <td>172.48</td>\n",
       "      <td>172.93</td>\n",
       "      <td>49675</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00</th>\n",
       "      <td>172.94</td>\n",
       "      <td>173.11</td>\n",
       "      <td>171.47</td>\n",
       "      <td>171.47</td>\n",
       "      <td>68973</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 06:00:00</th>\n",
       "      <td>171.49</td>\n",
       "      <td>174.31</td>\n",
       "      <td>171.34</td>\n",
       "      <td>173.22</td>\n",
       "      <td>95595</td>\n",
       "      <td>1.538259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 07:00:00</th>\n",
       "      <td>173.22</td>\n",
       "      <td>173.74</td>\n",
       "      <td>172.26</td>\n",
       "      <td>172.47</td>\n",
       "      <td>95494</td>\n",
       "      <td>1.736148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:00:00</th>\n",
       "      <td>172.45</td>\n",
       "      <td>173.44</td>\n",
       "      <td>172.14</td>\n",
       "      <td>173.16</td>\n",
       "      <td>57926</td>\n",
       "      <td>1.554090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open    High     Low   Close  Volume    signal\n",
       "timestamp                                                            \n",
       "2022-01-01 04:00:00  172.79  173.13  172.48  172.93   49675  1.000000\n",
       "2022-01-01 05:00:00  172.94  173.11  171.47  171.47   68973  2.000000\n",
       "2022-01-01 06:00:00  171.49  174.31  171.34  173.22   95595  1.538259\n",
       "2022-01-01 07:00:00  173.22  173.74  172.26  172.47   95494  1.736148\n",
       "2022-01-01 08:00:00  172.45  173.44  172.14  173.16   57926  1.554090"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol = vbt.Data.from_data(df)\n",
    "\n",
    "features = df_sol.run(\"talib\", mavp=vbt.run_arg_dict(periods=14))\n",
    "\n",
    "df_sol.data['symbol'] = pd.concat([df_sol.data['symbol'], features], axis=1)\n",
    "# This will drop columns from the DataFrame where all values are NaN\n",
    "df_sol.data['symbol'] = df_sol.data['symbol'].dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "df_sol.data['symbol'] = df_sol.data['symbol'].dropna()\n",
    "predictor_list = df_sol.data['symbol'].drop('signal', axis=1).columns.tolist()\n",
    "X = df_sol.data['symbol'][predictor_list]\n",
    "\n",
    "y = df_sol.data['symbol']['signal']\n",
    "\n",
    "X.columns = X.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to create train, test data given stock data and sequence length\n",
    "# def load_data(stock, look_back):\n",
    "#     data_raw = stock.values # convert to numpy array\n",
    "#     data = []\n",
    "    \n",
    "#     # create all possible sequences of length look_back\n",
    "#     for index in range(len(data_raw) - look_back): \n",
    "#         data.append(data_raw[index: index + look_back])\n",
    "    \n",
    "#     data = np.array(data);\n",
    "#     # print(data[0, :, -1])\n",
    "#     test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "#     train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "#     x_train = data[:train_set_size,:-1,:-1]\n",
    "#     y_train = data[:train_set_size,-1,-1:]\n",
    "    \n",
    "#     x_test = data[train_set_size:,:-1,:-1]\n",
    "#     y_test = data[train_set_size:,-1,-1:]\n",
    "    \n",
    "#     return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "# look_back = 40 # choose sequence length\n",
    "# x_train, y_train, x_test, y_test = load_data(df_sol.data['symbol'], look_back)\n",
    "# print('x_train.shape = ',x_train.shape)\n",
    "# print('y_train.shape = ',y_train.shape)\n",
    "# print('x_test.shape = ',x_test.shape)\n",
    "# print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "# Assuming X is a DataFrame or a NumPy array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "\n",
    "# First, split your data into a training+validation set and a separate test set\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.3, shuffle=False)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20\n",
    "\n",
    "def create_sequences(input_data, timestep):\n",
    "    sequences = []\n",
    "    data_len = len(input_data)\n",
    "    for i in range(data_len - timestep):\n",
    "        seq = input_data[i:(i + timestep)]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "X_train_list = create_sequences(X_train_scaled, timestep)\n",
    "X_test_list = create_sequences(X_test_scaled, timestep)\n",
    "y_train_seq_ar = y_train[timestep:]\n",
    "y_test_seq_ar = y_test[timestep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x_train_ar = np.array(X_train_list)\n",
    "x_test_ar = np.array(X_test_list)  \n",
    "\n",
    "y_train_seq = np.array(y_train_seq_ar).reshape(-1, 1)\n",
    "y_test_seq = np.array(y_test_seq_ar).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training and test sets in torch\n",
    "x_train_tensor = torch.from_numpy(x_train_ar).type(torch.Tensor)\n",
    "x_test_tensor = torch.from_numpy(x_test_ar).type(torch.Tensor)\n",
    "y_train_tensor = torch.from_numpy(y_train_seq).type(torch.Tensor)\n",
    "y_test_tensor = torch.from_numpy(y_test_seq).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12167, 1]), torch.Size([12167, 20, 178]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.size(),x_train_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "#####################\n",
    "input_dim = x_train_tensor.shape[2]\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # Dynamically obtain the batch size from input\n",
    "        hn, cn = self.init_hidden(batch_size)  # Initialize hidden and cell states based on batch size\n",
    "        out, (hn, cn) = self.lstm(x, (hn, cn))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, (hn, cn)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Generate the initial hidden state and cell state without requiring gradients\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n",
    "\n",
    "\n",
    "    \n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#####################\n",
    "num_epochs = 100\n",
    "hist = np.zeros(num_epochs)  \n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming x_train and y_train are numpy arrays\n",
    "\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over batches in the dataset\n",
    "    for data, targets in train_loader:\n",
    "        model.zero_grad()\n",
    "        outputs, _ = model(data)  # Hidden states are now initialized inside the model\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # make predictions\n",
    "    y_test_pred = model(x_test_tensor)\n",
    "\n",
    "    # # y_train = y_train.detach().numpy()\n",
    "    # # y_test = y_test.detach().numpy()\n",
    "    # y_train_pred = outputs.detach().numpy()\n",
    "    # y_test_pred = y_test_pred.detach().numpy()\n",
    "\n",
    "    # # Calculate RMSE directly without inverse transformation\n",
    "    # trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "    # print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    # testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "    # print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my_test_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = pd.Series(y_test[timestep:])\n",
    "pred_sig = pd.Series(y_test_pred.flatten())\n",
    "pred_sig.index = signal.index\n",
    "combined_df = pd.concat([signal, pred_sig], axis=1)\n",
    "fig = combined_df.vbt.plot()\n",
    "fig.update_layout(yaxis_title='signal')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_entries = pred_sig > 1.35\n",
    "long_exits = pred_sig < 1\n",
    "short_entries = pred_sig < 0.5\n",
    "short_exits = pred_sig > 1.2\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=X_test.Close, \n",
    "    long_entries=long_entries, \n",
    "    long_exits=long_exits, \n",
    "    # short_entries=short_entries,\n",
    "    # short_exits=short_exits,\n",
    "    size=100,\n",
    "    size_type='value',\n",
    "    # accumulate=True,\n",
    "    init_cash='auto'\n",
    ")\n",
    "pf.plot({\"orders\", \"cum_returns\"}, settings=dict(bm_returns=False)).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming df_sol is your original DataFrame and y_test, y_test_pred are your numpy arrays\n",
    "# # First, create the index you want to use for the x-axis\n",
    "# x_axis_index = df[len(df)-len(y_test):].index\n",
    "\n",
    "# # Create Series with the custom index\n",
    "# y_test_series = pd.Series(y_test.flatten(), index=x_axis_index, name=\"Actual\")\n",
    "# y_test_pred_series = pd.Series(y_test_pred.flatten(), index=x_axis_index, name=\"Predicted\")\n",
    "\n",
    "# # Create a DataFrame from your series\n",
    "# combined_df = pd.DataFrame({\n",
    "#     \"Actual\": y_test_series,\n",
    "#     \"Predicted\": y_test_pred_series\n",
    "# })\n",
    "# entries = 2\n",
    "# exits = 0\n",
    "\n",
    "# combined_df['Actual_Diff'] = combined_df['Actual'].diff()\n",
    "# combined_df['Predicted_Diff'] = combined_df['Predicted'].diff()\n",
    "\n",
    "\n",
    "# cross_over = (combined_df['Actual_Diff'] > 0) & (combined_df['Actual'] > combined_df['Predicted']) & (combined_df['Actual'].shift(1) <= combined_df['Predicted'].shift(1))\n",
    "# cross_under = (combined_df['Actual_Diff'] < 0) & (combined_df['Actual'] < combined_df['Predicted']) & (combined_df['Actual'].shift(1) >= combined_df['Predicted'].shift(1))\n",
    "\n",
    "# combined_df['Signal'] = 1  # Default to '1' for hold/no action\n",
    "# combined_df.loc[cross_over, 'Signal'] = 2  # '2' for cross over\n",
    "# combined_df.loc[cross_under, 'Signal'] = 0  # '0' for cross under\n",
    "\n",
    "\n",
    "# # Plot using vectorbt\n",
    "# combined_df_vbt = vbt.Data.from_data(combined_df)\n",
    "# fig = combined_df_vbt.plot(trace_kwargs=dict(mode='lines'))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
